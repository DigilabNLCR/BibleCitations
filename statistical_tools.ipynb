{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STatistical tools for BiblicalIntertextuality\n",
    "\n",
    "This jupyter notebook contains functions that allows you to process statistics out of the data corpus (both journals and the Bible) and out of the results file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import biblical_intertextuality_package as bip\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import joblib\n",
    "from nltk import word_tokenize\n",
    "\n",
    "from biblical_intertextuality_package import split_verse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = os.getcwd()\n",
    "\n",
    "BIBLES_PATH = os.path.join(ROOT_PATH, 'Bible_files')\n",
    "DATASETS_PATH = os.path.join(ROOT_PATH, 'datasets')\n",
    "DICTS_PATH = os.path.join(ROOT_PATH, 'dictionaries')\n",
    "CORPUS_PATH = os.path.join(ROOT_PATH, 'corpuses')\n",
    "ALL_JSONS_PATH = os.path.join(ROOT_PATH, 'query_jsons')\n",
    "\n",
    "JOURNAL_FULLDATA_PATH = os.path.join(ROOT_PATH, 'journals_fulldata.joblib')\n",
    "\n",
    "# RESULTS_PATH = os.path.join(ROOT_PATH, 'results')\n",
    "RESULTS_PATH = os.path.join(ROOT_PATH, 'PUBLIC_RESULTS')\n",
    "BATCHES_FILE_PATH = os.path.join(ROOT_PATH, 'batches.csv')\n",
    "BATCH_RESULTS_FILE_PATH = os.path.join(RESULTS_PATH, 'batch_results.csv')\n",
    "\n",
    "STOP_WORDS_PATH = os.path.join(ROOT_PATH, 'stop_words.txt')\n",
    "STOP_SUBVERSES_PATH = os.path.join(ROOT_PATH, 'stop_subverses_21.txt')\n",
    "EXCLUSIVES_PATH = os.path.join(ROOT_PATH, 'exclusives.txt')\n",
    "\n",
    "EVALUATION_STOP_SUBVERSES_PATH = os.path.join(ROOT_PATH, 'evaluation_stop_subverses_21.txt')\n",
    "FULL_HIT_NEEDED_SUBS_PATH = os.path.join(ROOT_PATH, '100_hit_needed_subs_21.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Bible statistics\n",
    "Following functions return statistics about Bible files as stored in Bible_files directory. Be aware that we as the developers have an additional translation at our disposal ('Bible Svatováclavská') so your statistics will be probably different.\n",
    "\n",
    "- number of translations at our disposal: 5\n",
    "    - one is both Old and New Testament (\"Bible Kralická\")\n",
    "    - translation of Jan Hejčl: Old Testament + deuterocanonical books\n",
    "    - \"Bible of the Saint Venceslas\": mix of Old and New Testament, not complete (even some individual verses are missing)\n",
    "    - translation of Ladislav Sýkora: New Testament\n",
    "    - translation of František Žilka: New Testament"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "translation_names = {'BKR': 'Bible Kralická', 'BSV': 'Bible Svatováclavská', 'HEJCL': 'Jan Hejčl', 'SYK': 'Ladislav Sýkora', 'ZP': 'František Žilka'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_book_filename_data(bible_file_name:str):\n",
    "    bible_file_name = bible_file_name[:-4]\n",
    "    filename_parts = bible_file_name.split('_')\n",
    "\n",
    "    translation = filename_parts[1]\n",
    "    book_name = filename_parts[2]\n",
    "\n",
    "    return translation, book_name\n",
    "\n",
    "\n",
    "def analise_the_bible():\n",
    "    \"\"\"\n",
    "    This function analyses all data in the Bible_files directory. You can change split_verse settings if you have created your dataset with different settings.\n",
    "    \n",
    "    It prints following statistics:\n",
    "    - number of translations and their abbreviated names\n",
    "    - number of books (in aggregation and for each translation separately)\n",
    "    - number of verses (by verse_id, all in aggregation, and for each translation separately)\n",
    "    - number of subverses (in aggregation and for each translation separately)\n",
    "\n",
    "    And it saves csv file with statistics of books, verses and subverses for each translation (into RESULTS_PATH (by defaut now PUBLIC_RESULTS directory) --> statistics).\n",
    "    \"\"\"\n",
    "    all_bible_files = os.listdir(BIBLES_PATH)\n",
    "\n",
    "    translations = []\n",
    "    \n",
    "    books_names = []\n",
    "    books_aggregated = 0\n",
    "    books_per_trsl = defaultdict(int)\n",
    "\n",
    "    verse_ids = []\n",
    "    verses_aggregated = 0\n",
    "    verses_per_trsl = defaultdict(int)\n",
    "\n",
    "    subverses_aggregated = 0\n",
    "    subverses_per_trsl = defaultdict(int)\n",
    "\n",
    "    words_aggregated = 0\n",
    "    words_per_trsl = defaultdict(int)\n",
    "\n",
    "    for bible_file in all_bible_files:\n",
    "        translation, book_name = get_book_filename_data(bible_file)\n",
    "        \n",
    "        translations.append(translation)\n",
    "\n",
    "        books_names.append(book_name)\n",
    "        books_aggregated += 1\n",
    "        books_per_trsl[translation] += 1\n",
    "\n",
    "        with open(os.path.join(BIBLES_PATH, bible_file), 'r', encoding='utf-8') as b_file:\n",
    "            data = b_file.read()\n",
    "            verses = eval(data)\n",
    "\n",
    "            for verse_id in verses:\n",
    "                verse_ids.append(verse_id)\n",
    "                verses_aggregated += 1\n",
    "                verses_per_trsl[translation] += 1\n",
    "\n",
    "                words_in_verse = bip.word_tokenize_no_punctuation(verses[verse_id])\n",
    "                words_per_trsl[translation] += len(words_in_verse)\n",
    "                words_aggregated += len(words_in_verse)\n",
    "\n",
    "                subverses = split_verse(verses[verse_id])\n",
    "\n",
    "                subverses_aggregated += len(subverses)\n",
    "                subverses_per_trsl[translation] += len(subverses)\n",
    "\n",
    "    translations = list(set(translations))\n",
    "\n",
    "    print(translations)\n",
    "    print('Numebr of translations:', len(translations))\n",
    "\n",
    "    print()\n",
    "\n",
    "    books_names = list(set(books_names))\n",
    "    print('Number of available books:', len(books_names))\n",
    "    print('Number of books accross translations:', books_aggregated)\n",
    "    for trsl in books_per_trsl:\n",
    "        print('Number of books in', trsl, 'is', books_per_trsl[trsl])\n",
    "\n",
    "    print()\n",
    "\n",
    "    verse_ids = list(set(verse_ids))\n",
    "    print('Number of available verses:', len(verse_ids))\n",
    "    print('Number of verses accross translations:', verses_aggregated)\n",
    "    for trsl in verses_per_trsl:\n",
    "        print('Number of verses in', trsl, 'is', verses_per_trsl[trsl])\n",
    "\n",
    "    print()\n",
    "    \n",
    "    print('Total number of subverses:', subverses_aggregated)\n",
    "    for trsl in subverses_per_trsl:\n",
    "        print('Number of subverses in', trsl, 'is', subverses_per_trsl[trsl])\n",
    "\n",
    "    print('Total number of words:', words_aggregated)\n",
    "    for trsl in words_per_trsl:\n",
    "        print('Number of words in', trsl, 'is', words_per_trsl[trsl])\n",
    "\n",
    "    df_dict = {'translation': [], 'books': [], 'verses': [], 'subverses': [], 'words': []}\n",
    "    for trsl in translations:\n",
    "        df_dict['translation'].append(trsl)\n",
    "        df_dict['books'].append(books_per_trsl[trsl])\n",
    "        df_dict['verses'].append(verses_per_trsl[trsl])\n",
    "        df_dict['subverses'].append(subverses_per_trsl[trsl])\n",
    "        df_dict['words'].append(words_per_trsl[trsl])\n",
    "\n",
    "    \n",
    "    bible_stats_df = pd.DataFrame(df_dict)\n",
    "    bible_stats_df.to_csv(os.path.join(RESULTS_PATH, 'statistics', 'bible_stats.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BKR', 'BSV', 'SYK', 'ZP', 'HEJCL']\n",
      "Numebr of translations: 5\n",
      "\n",
      "Number of available books: 74\n",
      "Number of books accross translations: 202\n",
      "Number of books in BKR is 66\n",
      "Number of books in BSV is 37\n",
      "Number of books in HEJCL is 47\n",
      "Number of books in SYK is 26\n",
      "Number of books in ZP is 26\n",
      "\n",
      "Number of available verses: 36745\n",
      "Number of verses accross translations: 89485\n",
      "Number of verses in BKR is 31172\n",
      "Number of verses in BSV is 15326\n",
      "Number of verses in HEJCL is 27896\n",
      "Number of verses in SYK is 7541\n",
      "Number of verses in ZP is 7550\n",
      "\n",
      "Total number of subverses: 329867\n",
      "Number of subverses in BKR is 121283\n",
      "Number of subverses in BSV is 55660\n",
      "Number of subverses in HEJCL is 103523\n",
      "Number of subverses in SYK is 24786\n",
      "Number of subverses in ZP is 24615\n",
      "Total number of words: 1620772\n",
      "Number of words in BKR is 594928\n",
      "Number of words in BSV is 267069\n",
      "Number of words in HEJCL is 505218\n",
      "Number of words in SYK is 128436\n",
      "Number of words in ZP is 125121\n"
     ]
    }
   ],
   "source": [
    "analise_the_bible()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Journals data statistics\n",
    "\n",
    "The following section contains functions that facilitace journals statistics. Since the sournals data are not availabe within the GitHub repository, these functions are pretty much useless for you, unles you wish to analyse your own datasets.\n",
    "\n",
    "- NOTE: this process also revelas some mistakes in the dataset. For example Čech no. 26 from 1935 has no marked date in our dataset and [online](https://kramerius5.nkp.cz/view/uuid:334149b0-877c-11e6-8aeb-5ef3fc9ae867) is marek as issued in 1927. In general, such mistakes are ignored because statistically insignificant, but the researches should be avere of these problems (and may repair such mistakes in their datasets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_journals():\n",
    "    \"\"\"\n",
    "    This function analyses the available journal files (based on the 'journals_fulldata.joblib' file)\n",
    "\n",
    "    It prints following data:\n",
    "    - number of analysed journals\n",
    "    - number of years that each journal covers\n",
    "    - number of issues per journal\n",
    "    - number of pages per journal\n",
    "    - number of charaters per journal\n",
    "    - average characters per page per journal\n",
    "    \"\"\"\n",
    "    # NOTE: because we are following only years 1925-1939, we are ignoring those that are outside of this scope... '1937-1938' is added because it fits the profile, too...\n",
    "    years_to_consider = ['1925', '1926', '1927', '1928', '1929', '1930', '1931', '1932', '1933', '1934', '1935', '1936', '1937', '1938', '1939', '1937-1938']\n",
    "\n",
    "    journals_fulldata_dict = joblib.load(JOURNAL_FULLDATA_PATH)\n",
    "\n",
    "    journals = []\n",
    "    years_per_yournal = defaultdict(list)\n",
    "    issues_per_journal = defaultdict(list)\n",
    "    pages_per_journal = defaultdict(int)\n",
    "    characters_per_journal = defaultdict(int)\n",
    "\n",
    "    words_aggregated = 0\n",
    "    words_per_journal = defaultdict(int)\n",
    "\n",
    "    uuids_out_of_the_scope = []\n",
    "    years_out_of_scope = []\n",
    "    uuids_without_date = []\n",
    "    \n",
    "    for uuid_file in journals_fulldata_dict:\n",
    "        uuid_file_data = journals_fulldata_dict[uuid_file]\n",
    "        \n",
    "        journal = uuid_file_data['journal']\n",
    "        issue_date = uuid_file_data['issue_date']\n",
    "        \n",
    "        if issue_date == '':\n",
    "            uuids_without_date.append(uuid_file)\n",
    "            continue\n",
    "        else:\n",
    "            date_parts = issue_date.split('.')\n",
    "            issue_year = date_parts[-1]\n",
    "\n",
    "            if issue_year in years_to_consider:\n",
    "                if issue_year not in years_per_yournal[journal]:\n",
    "                    if issue_year == '1937-1938':\n",
    "                        continue\n",
    "                    else:\n",
    "                        years_per_yournal[journal].append(issue_year)\n",
    "        \n",
    "                if journal not in journals:\n",
    "                    journals.append(journal)                \n",
    "\n",
    "                uuid = uuid_file_data['issue_uuid']\n",
    "                if uuid not in issues_per_journal[journal]:\n",
    "                    issues_per_journal[journal].append(uuid)\n",
    "\n",
    "                pages_per_journal[journal] += 1\n",
    "\n",
    "                characters_per_journal[journal] += len(uuid_file_data['text'])\n",
    "\n",
    "                words_in_page = len(bip.word_tokenize_no_punctuation(uuid_file_data['text']))\n",
    "                words_per_journal[journal] += words_in_page\n",
    "                words_aggregated += words_in_page\n",
    "\n",
    "            \n",
    "            else:\n",
    "                uuids_out_of_the_scope.append(uuid_file)\n",
    "                years_out_of_scope.append(issue_year)\n",
    "\n",
    "    print('Number of analysed journals:', len(journals))\n",
    "\n",
    "    print()\n",
    "\n",
    "    for journal in journals:\n",
    "        years_per_yournal[journal].sort()\n",
    "        print(journal)\n",
    "        print(f'\\tYears in journal ({len(years_per_yournal[journal])}):', years_per_yournal[journal])\n",
    "        print('\\tIssues in journal:', len(issues_per_journal[journal]))\n",
    "        print('\\tPages in journal:', pages_per_journal[journal])\n",
    "        print('\\tCharacter in journal:', characters_per_journal[journal])\n",
    "        print('\\tWords in journal:', words_per_journal[journal])\n",
    "        print('\\tAverage characters per page in journal:', characters_per_journal[journal]/pages_per_journal[journal])\n",
    "\n",
    "    print()\n",
    "\n",
    "    print('Total number of words in analysed journals:', words_aggregated)\n",
    "\n",
    "    print()\n",
    "\n",
    "    print('Number of files that do not fit the time range:', len(uuids_out_of_the_scope), set(years_out_of_scope))\n",
    "    print('Number of files that do not have date in the metadata:', len(uuids_without_date))\n",
    "\n",
    "    df_dict = {'journal': [], 'years': [], 'issues': [], 'pages': [], 'standard pages': [], 'words': [], 'characters': []}\n",
    "    for journal in journals:\n",
    "        df_dict['journal'].append(journal)\n",
    "        df_dict['years'].append(len(years_per_yournal[journal]))\n",
    "        df_dict['issues'].append(len(issues_per_journal[journal]))\n",
    "        df_dict['pages'].append(pages_per_journal[journal])\n",
    "        df_dict['standard pages'].append(characters_per_journal[journal]/1800)\n",
    "        df_dict['words'].append(words_per_journal[journal])\n",
    "        df_dict['characters'].append(characters_per_journal[journal])\n",
    "\n",
    "    \n",
    "    journals_stats_df = pd.DataFrame(df_dict)\n",
    "    journals_stats_df.to_csv(os.path.join(RESULTS_PATH, 'statistics', 'journals_stats.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of analysed journals: 11\n",
      "\n",
      "Čech\n",
      "\tYears in journal (10): ['1925', '1926', '1927', '1928', '1929', '1930', '1931', '1932', '1933', '1934']\n",
      "\tIssues in journal: 2368\n",
      "\tPages in journal: 15678\n",
      "\tCharacter in journal: 145508697\n",
      "\tWords in journal: 22978292\n",
      "\tAverage characters per page in journal: 9281.075200918485\n",
      "Československý zemědělec\n",
      "\tYears in journal (15): ['1925', '1926', '1927', '1928', '1929', '1930', '1931', '1932', '1933', '1934', '1935', '1936', '1937', '1938', '1939']\n",
      "\tIssues in journal: 753\n",
      "\tPages in journal: 9278\n",
      "\tCharacter in journal: 91147459\n",
      "\tWords in journal: 14081975\n",
      "\tAverage characters per page in journal: 9824.04171157577\n",
      "Český učitel\n",
      "\tYears in journal (15): ['1925', '1926', '1927', '1928', '1929', '1930', '1931', '1932', '1933', '1934', '1935', '1936', '1937', '1938', '1939']\n",
      "\tIssues in journal: 534\n",
      "\tPages in journal: 11580\n",
      "\tCharacter in journal: 57198594\n",
      "\tWords in journal: 8837564\n",
      "\tAverage characters per page in journal: 4939.429533678756\n",
      "Moravský hospodář\n",
      "\tYears in journal (15): ['1925', '1926', '1927', '1928', '1929', '1930', '1931', '1932', '1933', '1934', '1935', '1936', '1937', '1938', '1939']\n",
      "\tIssues in journal: 350\n",
      "\tPages in journal: 5683\n",
      "\tCharacter in journal: 27342938\n",
      "\tWords in journal: 4141664\n",
      "\tAverage characters per page in journal: 4811.356325884216\n",
      "Moravský večerník\n",
      "\tYears in journal (15): ['1925', '1926', '1927', '1928', '1929', '1930', '1931', '1932', '1933', '1934', '1935', '1936', '1937', '1938', '1939']\n",
      "\tIssues in journal: 4551\n",
      "\tPages in journal: 27907\n",
      "\tCharacter in journal: 308771689\n",
      "\tWords in journal: 48115458\n",
      "\tAverage characters per page in journal: 11064.309635575304\n",
      "Polední list\n",
      "\tYears in journal (4): ['1930', '1931', '1932', '1933']\n",
      "\tIssues in journal: 1632\n",
      "\tPages in journal: 10979\n",
      "\tCharacter in journal: 166354770\n",
      "\tWords in journal: 25998321\n",
      "\tAverage characters per page in journal: 15152.08762182348\n",
      "Posel záhrobní\n",
      "\tYears in journal (15): ['1925', '1926', '1927', '1928', '1929', '1930', '1931', '1932', '1933', '1934', '1935', '1936', '1937', '1938', '1939']\n",
      "\tIssues in journal: 150\n",
      "\tPages in journal: 2828\n",
      "\tCharacter in journal: 7106018\n",
      "\tWords in journal: 1145233\n",
      "\tAverage characters per page in journal: 2512.7362093352194\n",
      "Přítomnost\n",
      "\tYears in journal (15): ['1925', '1926', '1927', '1928', '1929', '1930', '1931', '1932', '1933', '1934', '1935', '1936', '1937', '1938', '1939']\n",
      "\tIssues in journal: 775\n",
      "\tPages in journal: 14996\n",
      "\tCharacter in journal: 92878244\n",
      "\tWords in journal: 14444426\n",
      "\tAverage characters per page in journal: 6193.5345425446785\n",
      "Studentský časopis\n",
      "\tYears in journal (15): ['1925', '1926', '1927', '1928', '1929', '1930', '1931', '1932', '1933', '1934', '1935', '1936', '1937', '1938', '1939']\n",
      "\tIssues in journal: 145\n",
      "\tPages in journal: 5410\n",
      "\tCharacter in journal: 28280046\n",
      "\tWords in journal: 4548945\n",
      "\tAverage characters per page in journal: 5227.365249537893\n",
      "Venkov\n",
      "\tYears in journal (15): ['1925', '1926', '1927', '1928', '1929', '1930', '1931', '1932', '1933', '1934', '1935', '1936', '1937', '1938', '1939']\n",
      "\tIssues in journal: 4589\n",
      "\tPages in journal: 60994\n",
      "\tCharacter in journal: 1102530937\n",
      "\tWords in journal: 171088676\n",
      "\tAverage characters per page in journal: 18076.05562842247\n",
      "Věstník katolického duchovenstva\n",
      "\tYears in journal (15): ['1925', '1926', '1927', '1928', '1929', '1930', '1931', '1932', '1933', '1934', '1935', '1936', '1937', '1938', '1939']\n",
      "\tIssues in journal: 175\n",
      "\tPages in journal: 1930\n",
      "\tCharacter in journal: 10213262\n",
      "\tWords in journal: 1592117\n",
      "\tAverage characters per page in journal: 5291.845595854922\n",
      "\n",
      "Total number of words in analysed journals: 316972671\n",
      "\n",
      "Number of files that do not fit the time range: 458 {'1924', '2016'}\n",
      "Number of files that do not have date in the metadata: 0\n"
     ]
    }
   ],
   "source": [
    "analyse_journals()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runtime statistics\n",
    "Statistics of runtimes - based on batches.csv file (the runtimes are always averages per batch, not per single documents!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_runtimes():\n",
    "    \"\"\"\n",
    "    This function analyses runtimes from the batches.csv file.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(os.path.join(ROOT_PATH, 'batches.csv'), quotechar='\"', delimiter=',', encoding='utf-8')\n",
    "\n",
    "    journals_full_names = ['Moravský hospodář', 'Polední list', 'Moravský večerník', 'Věstník katolického duchovenstva', 'Přítomnost', 'Venkov', 'Studentský časopis', 'Československý zemědělec', 'Český učitel', 'Čech', 'Posel záhrobní']\n",
    "    journals_filenames = ['moravsky_hospodar', 'poledni_list', 'moravsky_vecernik', 'vestnik_katolickeho_duchovenstva', 'pritomnost', 'venkov', 'studentsky_casopis', 'ceskoslovensky_zemedelec', 'cesky_ucitel', 'cech', 'posel_zahrobni']\n",
    "\n",
    "    all_times = []\n",
    "    results = {}\n",
    "    \n",
    "    for i, journal in enumerate(journals_filenames):\n",
    "        subset_dataframe = df[df['journal'] == journal]\n",
    "        journal_runtimes = defaultdict(int)\n",
    "        for row_id in subset_dataframe.index:\n",
    "            runtime = subset_dataframe.loc[row_id]['runtime']\n",
    "            if runtime >= 15:\n",
    "                # ignoring wierdly long runtimes (probably due to computer in sleep mode...)\n",
    "                continue\n",
    "            else:\n",
    "                journal_runtimes[round(runtime, 1)] += 1\n",
    "                all_times.append(round(runtime, 1))\n",
    "\n",
    "        print(journals_full_names[i], journal_runtimes)\n",
    "        results[journals_full_names[i]] = journal_runtimes\n",
    "    \n",
    "    all_times_full = [round(i, 1) for i in np.arange(0, 10, 0.1)]\n",
    "\n",
    "    output_dict = {}\n",
    "    out_idx = 0\n",
    "    \n",
    "    for res in results:\n",
    "        journal_data = {}\n",
    "        journal_data['journal'] = res\n",
    "        for timestamp in all_times_full:\n",
    "            try:\n",
    "                journal_data[timestamp] = results[res][timestamp]\n",
    "            except IndexError:\n",
    "                journal_data[timestamp] = 0\n",
    "        \n",
    "        output_dict[out_idx] = journal_data\n",
    "        out_idx += 1\n",
    "\n",
    "    output_df = pd.DataFrame.from_dict(output_dict)\n",
    "    output_df = output_df.transpose()\n",
    "\n",
    "    output_df.to_csv(os.path.join(RESULTS_PATH, 'statistics', 'runtimes_stats.csv'), quotechar='\"', sep=',', encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moravský hospodář defaultdict(<class 'int'>, {0.8: 1880, 0.7: 1880, 0.9: 520, 0.6: 1200, 0.5: 160, 1.1: 40, 1.8: 3})\n",
      "Polední list defaultdict(<class 'int'>, {2.4: 3480, 2.5: 1960, 2.6: 2360, 2.2: 640, 2.3: 1600, 2.7: 360, 2.8: 280, 2.9: 40, 2.1: 240, 1.0: 19})\n",
      "Moravský večerník defaultdict(<class 'int'>, {1.8: 5480, 2.1: 3600, 2.0: 4480, 1.9: 4280, 1.6: 2160, 1.7: 3000, 2.2: 1960, 2.3: 720, 1.4: 160, 1.5: 1000, 2.4: 673, 1.3: 80, 2.6: 120, 2.7: 40, 2.5: 160})\n",
      "Věstník katolického duchovenstva defaultdict(<class 'int'>, {1.9: 40, 1.0: 400, 1.3: 120, 1.2: 480, 1.1: 680, 0.9: 200, 1.4: 40, 0.0: 2})\n",
      "Přítomnost defaultdict(<class 'int'>, {0.9: 40, 1.5: 4080, 1.3: 1800, 1.4: 4396, 1.6: 2600, 1.2: 880, 1.7: 640, 1.8: 320, 2.1: 40, 1.1: 80, 2.8: 40, 1.9: 40, 2.0: 40})\n",
      "Venkov defaultdict(<class 'int'>, {2.4: 760, 3.6: 920, 3.2: 7480, 3.4: 2880, 2.9: 7760, 2.8: 7240, 3.5: 1440, 3.1: 8960, 3.3: 4480, 3.8: 320, 3.0: 10120, 2.7: 3560, 2.6: 2080, 2.5: 800, 2.2: 400, 2.3: 240, 3.7: 280, 4.3: 120, 3.9: 80, 4.0: 40, 4.1: 120, 4.4: 40, 4.2: 40, 1.7: 80, 1.3: 80, 2.1: 160, 2.0: 120, 1.9: 114, 1.6: 120, 1.8: 40, 1.1: 40})\n",
      "Studentský časopis defaultdict(<class 'int'>, {1.4: 40, 1.1: 800, 1.0: 2120, 1.2: 240, 0.9: 1680, 0.8: 640, 2.4: 26})\n",
      "Československý zemědělec defaultdict(<class 'int'>, {2.0: 680, 2.8: 160, 2.9: 160, 2.4: 320, 3.1: 40, 1.7: 680, 2.5: 160, 2.6: 240, 2.3: 360, 1.9: 560, 3.0: 80, 2.7: 160, 2.2: 560, 2.1: 440, 3.3: 40, 4.3: 40, 4.9: 40, 5.8: 40, 4.4: 40, 1.8: 1040, 1.4: 920, 1.5: 1240, 1.6: 1000, 1.3: 200, 1.2: 78})\n",
      "Český učitel defaultdict(<class 'int'>, {1.2: 280, 1.0: 4120, 1.1: 760, 0.8: 2224, 0.9: 4120, 0.6: 200, 0.7: 160})\n",
      "Čech defaultdict(<class 'int'>, {1.8: 6240, 1.7: 2240, 1.9: 4320, 2.2: 120, 2.0: 1718, 2.1: 560, 1.5: 80, 1.6: 400})\n",
      "Posel záhrobní defaultdict(<class 'int'>, {1.0: 40, 0.8: 160, 0.6: 1400, 0.5: 320, 0.7: 840, 0.9: 72})\n"
     ]
    }
   ],
   "source": [
    "analyse_runtimes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results statistics\n",
    "\n",
    "The following section contains functions that facilitate results stiatistics\n",
    "\n",
    "### Overall statistics for journals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_journals = ['Moravský hospodář', 'Polední list', 'Moravský večerník', 'Věstník katolického duchovenstva', 'Přítomnost', 'Venkov', 'Studentský časopis', 'Československý zemědělec', 'Český učitel', 'Čech', 'Posel záhrobní']\n",
    "\n",
    "def ciation_counts_per_journal(results_filename:str, csv_delimiter=';'):\n",
    "    citations_dataframe = pd.read_csv(os.path.join(RESULTS_PATH, results_filename), quotechar='\"', delimiter=csv_delimiter, encoding='utf-8', index_col=0)\n",
    "\n",
    "    print('Total number of citations:', len(citations_dataframe))\n",
    "    \n",
    "    citations = {}\n",
    "    \n",
    "    for journal in all_journals:\n",
    "        journal_citations_df = citations_dataframe[citations_dataframe['journal'] == journal]\n",
    "        print(journal, len(journal_citations_df))\n",
    "        citations[journal] = len(journal_citations_df)\n",
    "\n",
    "    return citations\n",
    "\n",
    "\n",
    "def ciation_counts_per_journal_not_drop(results_filename:str, csv_delimiter=';'):\n",
    "    citations_dataframe = pd.read_csv(os.path.join(RESULTS_PATH, results_filename), quotechar='\"', delimiter=csv_delimiter, encoding='utf-8', index_col=0)\n",
    "\n",
    "    citations_dataframe = citations_dataframe[citations_dataframe['drop?'] == False]\n",
    "    \n",
    "    print('Total number of citations:', len(citations_dataframe))\n",
    "    \n",
    "    citations = {}\n",
    "    \n",
    "    for journal in all_journals:\n",
    "        journal_citations_df = citations_dataframe[citations_dataframe['journal'] == journal]\n",
    "        print(journal, len(journal_citations_df))\n",
    "        citations[journal] = len(journal_citations_df)\n",
    "\n",
    "    return citations\n",
    "\n",
    "\n",
    "def sure_ciations_counts_per_journal(results_filename:str, csv_delimiter=';'):\n",
    "    citations_dataframe = pd.read_csv(os.path.join(RESULTS_PATH, results_filename), quotechar='\"', delimiter=csv_delimiter, encoding='utf-8', index_col=0)\n",
    "\n",
    "    citations_dataframe = citations_dataframe[citations_dataframe['drop?'] == False]\n",
    "    citations_dataframe = citations_dataframe[citations_dataframe['CITATION'] == True]\n",
    "    \n",
    "    print('Total number of citations:', len(citations_dataframe))\n",
    "    \n",
    "    citations = {}\n",
    "    \n",
    "    for journal in all_journals:\n",
    "        journal_citations_df = citations_dataframe[citations_dataframe['journal'] == journal]\n",
    "        print(journal, len(journal_citations_df))\n",
    "        citations[journal] = len(journal_citations_df) \n",
    "    \n",
    "    return citations\n",
    "\n",
    "\n",
    "def get_overall_result_stats():\n",
    "    print('Filtered citations:')\n",
    "    filtered_citations = ciation_counts_per_journal('FILTERED_UNFILTERED_batch_results.csv')\n",
    "    print('\\nStop subs:')\n",
    "    after_stop_subs = ciation_counts_per_journal('ST_SUBS_FILTERED_UNFILTERED_batch_results.csv')\n",
    "    print('\\nMultiple attrs:')\n",
    "    multiple_attrs = ciation_counts_per_journal_not_drop('MUTUAL_DROP_SURE_MA_DUPS_ST_SUBS_FILTERED_UNFILTERED_batch_results.csv')\n",
    "    print('\\n\"Sure\" citations:')\n",
    "    sure_cites = sure_ciations_counts_per_journal('MUTUAL_DROP_SURE_MA_DUPS_ST_SUBS_FILTERED_UNFILTERED_batch_results.csv')\n",
    "\n",
    "    out_df_dict = {'journal': [], 'initial results': [], 'filtered stop-subverses': [], 'filtered multiple attributions': [], '\"sure\" citations': []}\n",
    "\n",
    "    for journal in all_journals:\n",
    "        out_df_dict['journal'].append(journal)\n",
    "        out_df_dict['initial results'].append(filtered_citations[journal])\n",
    "        out_df_dict['filtered stop-subverses'].append(after_stop_subs[journal])\n",
    "        out_df_dict['filtered multiple attributions'].append(multiple_attrs[journal])\n",
    "        out_df_dict['\"sure\" citations'].append(sure_cites[journal])\n",
    "\n",
    "    stats_df = pd.DataFrame(out_df_dict)\n",
    "    stats_df.to_csv(os.path.join(RESULTS_PATH, 'statistics', 'journals_results_stats.csv'))   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered citations:\n",
      "Total number of citations: 38039\n",
      "Moravský hospodář 285\n",
      "Polední list 2334\n",
      "Moravský večerník 4406\n",
      "Věstník katolického duchovenstva 2008\n",
      "Přítomnost 2205\n",
      "Venkov 14309\n",
      "Studentský časopis 506\n",
      "Československý zemědělec 1154\n",
      "Český učitel 1110\n",
      "Čech 8277\n",
      "Posel záhrobní 1445\n",
      "\n",
      "Stop subs:\n",
      "Total number of citations: 12137\n",
      "Moravský hospodář 4\n",
      "Polední list 209\n",
      "Moravský večerník 599\n",
      "Věstník katolického duchovenstva 1529\n",
      "Přítomnost 559\n",
      "Venkov 2212\n",
      "Studentský časopis 159\n",
      "Československý zemědělec 206\n",
      "Český učitel 386\n",
      "Čech 5237\n",
      "Posel záhrobní 1037\n",
      "\n",
      "Multiple attrs:\n",
      "Total number of citations: 7103\n",
      "Moravský hospodář 2\n",
      "Polední list 147\n",
      "Moravský večerník 381\n",
      "Věstník katolického duchovenstva 772\n",
      "Přítomnost 342\n",
      "Venkov 1528\n",
      "Studentský časopis 102\n",
      "Československý zemědělec 127\n",
      "Český učitel 225\n",
      "Čech 3022\n",
      "Posel záhrobní 455\n",
      "\n",
      "\"Sure\" citations:\n",
      "Total number of citations: 1239\n",
      "Moravský hospodář 0\n",
      "Polední list 17\n",
      "Moravský večerník 35\n",
      "Věstník katolického duchovenstva 219\n",
      "Přítomnost 53\n",
      "Venkov 180\n",
      "Studentský časopis 16\n",
      "Československý zemědělec 31\n",
      "Český učitel 39\n",
      "Čech 496\n",
      "Posel záhrobní 153\n"
     ]
    }
   ],
   "source": [
    "get_overall_result_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Citations in years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "years_to_plot = ['1925', '1926', '1927', '1928', '1929', '1930', '1931', '1932', '1933', '1934', '1935', '1936', '1937', '1938', '1939']\n",
    "\n",
    "def ciation_counts_per_year(results_filename:str, csv_delimiter=';'):\n",
    "    citations_dataframe = pd.read_csv(os.path.join(RESULTS_PATH, results_filename), quotechar='\"', delimiter=csv_delimiter, encoding='utf-8', index_col=0)\n",
    "    \n",
    "    citations = defaultdict(int)\n",
    "    \n",
    "    for row_id in citations_dataframe.index:\n",
    "        row_dict = citations_dataframe.loc[row_id].to_dict()\n",
    "        year = row_dict['date'].split('.')[-1]\n",
    "        citations[year] += 1\n",
    "\n",
    "    return citations\n",
    "\n",
    "\n",
    "def ciation_counts_per_year_not_drop(results_filename:str, csv_delimiter=';'):\n",
    "    citations_dataframe = pd.read_csv(os.path.join(RESULTS_PATH, results_filename), quotechar='\"', delimiter=csv_delimiter, encoding='utf-8', index_col=0)\n",
    "\n",
    "    citations_dataframe = citations_dataframe[citations_dataframe['drop?'] == False]\n",
    "    \n",
    "    citations = defaultdict(int)\n",
    "    \n",
    "    for row_id in citations_dataframe.index:\n",
    "        row_dict = citations_dataframe.loc[row_id].to_dict()\n",
    "        year = row_dict['date'].split('.')[-1]\n",
    "        citations[year] += 1\n",
    "\n",
    "    return citations\n",
    "\n",
    "\n",
    "def sure_ciations_counts_per_year(results_filename:str, csv_delimiter=';'):\n",
    "    citations_dataframe = pd.read_csv(os.path.join(RESULTS_PATH, results_filename), quotechar='\"', delimiter=csv_delimiter, encoding='utf-8', index_col=0)\n",
    "\n",
    "    citations_dataframe = citations_dataframe[citations_dataframe['drop?'] == False]\n",
    "    citations_dataframe = citations_dataframe[citations_dataframe['CITATION'] == True]\n",
    "    \n",
    "    citations = defaultdict(int)\n",
    "    \n",
    "    for row_id in citations_dataframe.index:\n",
    "        row_dict = citations_dataframe.loc[row_id].to_dict()\n",
    "        year = row_dict['date'].split('.')[-1]\n",
    "        citations[year] += 1\n",
    "    \n",
    "    return citations\n",
    "\n",
    "\n",
    "def results_in_years():\n",
    "    print('Filtered citations:')\n",
    "    filtered_citations = ciation_counts_per_year('FILTERED_UNFILTERED_batch_results.csv')\n",
    "    print(filtered_citations)\n",
    "    print('\\nStop subs:')\n",
    "    after_stop_subs = ciation_counts_per_year('ST_SUBS_FILTERED_UNFILTERED_batch_results.csv')\n",
    "    print(after_stop_subs)\n",
    "    print('\\nMultiple attrs:')\n",
    "    multiple_attrs = ciation_counts_per_year_not_drop('MUTUAL_DROP_SURE_MA_DUPS_ST_SUBS_FILTERED_UNFILTERED_batch_results.csv')\n",
    "    print(multiple_attrs)\n",
    "    print('\\n\"Sure\" citations:')\n",
    "    sure_cites = sure_ciations_counts_per_year('MUTUAL_DROP_SURE_MA_DUPS_ST_SUBS_FILTERED_UNFILTERED_batch_results.csv')\n",
    "    print(sure_cites)\n",
    "\n",
    "    out_df_dict = {'year': [], 'initial results': [], 'filtered stop-subverses': [], 'filtered multiple attributions': [], '\"sure\" citations': []}\n",
    "\n",
    "    for year in years_to_plot:\n",
    "        out_df_dict['year'].append(year)\n",
    "        out_df_dict['initial results'].append(filtered_citations[year])\n",
    "        out_df_dict['filtered stop-subverses'].append(after_stop_subs[year])\n",
    "        out_df_dict['filtered multiple attributions'].append(multiple_attrs[year])\n",
    "        out_df_dict['\"sure\" citations'].append(sure_cites[year])\n",
    "\n",
    "    stats_df = pd.DataFrame(out_df_dict)\n",
    "    stats_df.to_csv(os.path.join(RESULTS_PATH, 'statistics', 'years_results_stats.csv'))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered citations:\n",
      "defaultdict(<class 'int'>, {'1927': 3276, '1926': 2687, '1929': 2613, '1928': 2554, '1930': 2899, '1925': 3103, '1934': 2192, '1931': 3127, '1933': 3059, '1932': 2510, '1935': 2027, '1938': 1946, '1937': 2085, '1936': 2067, '1939': 1894})\n",
      "\n",
      "Stop subs:\n",
      "defaultdict(<class 'int'>, {'1927': 1336, '1926': 941, '1928': 828, '1930': 893, '1925': 1380, '1934': 827, '1933': 717, '1932': 699, '1929': 874, '1931': 1144, '1935': 577, '1938': 444, '1936': 481, '1939': 479, '1937': 517})\n",
      "\n",
      "Multiple attrs:\n",
      "defaultdict(<class 'int'>, {'1927': 758, '1926': 588, '1928': 535, '1930': 520, '1925': 803, '1934': 445, '1933': 450, '1932': 429, '1929': 537, '1931': 608, '1935': 321, '1938': 275, '1936': 273, '1939': 270, '1937': 291})\n",
      "\n",
      "\"Sure\" citations:\n",
      "defaultdict(<class 'int'>, {'1934': 121, '1926': 68, '1932': 76, '1928': 76, '1927': 130, '1933': 85, '1931': 92, '1925': 133, '1929': 81, '1930': 81, '1935': 85, '1938': 45, '1936': 59, '1939': 44, '1937': 63})\n"
     ]
    }
   ],
   "source": [
    "results_in_years()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top citations - full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ciation_counts_per_verses(results_filename:str, csv_delimiter=';'):\n",
    "    citations_dataframe = pd.read_csv(os.path.join(RESULTS_PATH, results_filename), quotechar='\"', delimiter=csv_delimiter, encoding='utf-8', index_col=0)\n",
    "    \n",
    "    citations = defaultdict(int)\n",
    "    \n",
    "    for row_id in citations_dataframe.index:\n",
    "        row_dict = citations_dataframe.loc[row_id].to_dict()\n",
    "        verse_id = row_dict['verse_id']\n",
    "        citations[verse_id] += 1\n",
    "\n",
    "    return citations\n",
    "\n",
    "def ciation_counts_per_verses_drop(results_filename:str, csv_delimiter=';'):\n",
    "    citations_dataframe = pd.read_csv(os.path.join(RESULTS_PATH, results_filename), quotechar='\"', delimiter=csv_delimiter, encoding='utf-8', index_col=0)\n",
    "    \n",
    "    citations_dataframe = citations_dataframe[citations_dataframe['drop?'] == False]\n",
    "\n",
    "    citations = defaultdict(int)\n",
    "    \n",
    "    for row_id in citations_dataframe.index:\n",
    "        row_dict = citations_dataframe.loc[row_id].to_dict()\n",
    "        verse_id = row_dict['verse_id']\n",
    "        citations[verse_id] += 1\n",
    "\n",
    "    return citations\n",
    "\n",
    "def ciation_counts_per_verses_sure(results_filename:str, csv_delimiter=';'):\n",
    "    citations_dataframe = pd.read_csv(os.path.join(RESULTS_PATH, results_filename), quotechar='\"', delimiter=csv_delimiter, encoding='utf-8', index_col=0)\n",
    "    \n",
    "    citations_dataframe = citations_dataframe[citations_dataframe['drop?'] == False]\n",
    "    citations_dataframe = citations_dataframe[citations_dataframe['CITATION'] == True]\n",
    "\n",
    "    citations = defaultdict(int)\n",
    "    \n",
    "    for row_id in citations_dataframe.index:\n",
    "        row_dict = citations_dataframe.loc[row_id].to_dict()\n",
    "        verse_id = row_dict['verse_id']\n",
    "        citations[verse_id] += 1\n",
    "\n",
    "    return citations\n",
    "\n",
    "def analyse_verses():\n",
    "    print('Filtered citations:')\n",
    "    filtered_citations = ciation_counts_per_verses('FILTERED_UNFILTERED_batch_results.csv')\n",
    "    print('\\nStop subs:')\n",
    "    after_stop_subs = ciation_counts_per_verses('ST_SUBS_FILTERED_UNFILTERED_batch_results.csv')\n",
    "    print('\\nMultiple attrs:')\n",
    "    multiple_attrs = ciation_counts_per_verses_drop('MUTUAL_DROP_SURE_MA_DUPS_ST_SUBS_FILTERED_UNFILTERED_batch_results.csv')\n",
    "    print('\\n\"Sure\" citations:')\n",
    "    sure_cites = ciation_counts_per_verses_sure('MUTUAL_DROP_SURE_MA_DUPS_ST_SUBS_FILTERED_UNFILTERED_batch_results.csv')\n",
    "\n",
    "    out_df_dict = {'verse': [], 'initial results': [], 'filtered stop-subverses': [], 'filtered multiple attributions': [], '\"sure\" citations': []}\n",
    "\n",
    "    for verse_id in filtered_citations:\n",
    "        out_df_dict['verse'].append(verse_id)\n",
    "        try:\n",
    "            out_df_dict['initial results'].append(filtered_citations[verse_id])\n",
    "        except:\n",
    "            out_df_dict['initial results'].append(0)\n",
    "        try:            \n",
    "            out_df_dict['filtered stop-subverses'].append(after_stop_subs[verse_id])\n",
    "        except:\n",
    "            out_df_dict['filtered stop-subverses'].append(0)\n",
    "        try:                \n",
    "            out_df_dict['filtered multiple attributions'].append(multiple_attrs[verse_id])\n",
    "        except:\n",
    "            out_df_dict['filtered multiple attributions'].append(0)\n",
    "        try:                \n",
    "            out_df_dict['\"sure\" citations'].append(sure_cites[verse_id])\n",
    "        except:\n",
    "            out_df_dict['\"sure\" citations'].append(0)\n",
    "\n",
    "    stats_df = pd.DataFrame(out_df_dict)\n",
    "    stats_df.to_csv(os.path.join(RESULTS_PATH, 'statistics', 'verse_results_stats.csv'))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered citations:\n",
      "\n",
      "Stop subs:\n",
      "\n",
      "Multiple attrs:\n",
      "\n",
      "\"Sure\" citations:\n"
     ]
    }
   ],
   "source": [
    "analyse_verses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ciation_counts_per_verses_for_top(results_filename:str, csv_delimiter=';'):\n",
    "    citations_dataframe = pd.read_csv(os.path.join(RESULTS_PATH, results_filename), quotechar='\"', delimiter=csv_delimiter, encoding='utf-8', index_col=0)\n",
    "    \n",
    "    citations_dataframe = citations_dataframe[citations_dataframe['drop?'] == False]\n",
    "\n",
    "    citations = defaultdict(int)\n",
    "    verse_texts = defaultdict(list)\n",
    "    \n",
    "    for row_id in citations_dataframe.index:\n",
    "        row_dict = citations_dataframe.loc[row_id].to_dict()\n",
    "        verse_id = row_dict['verse_id']\n",
    "        verse_text = row_dict['verse_text']\n",
    "        citations[verse_id] += 1\n",
    "        if verse_text not in verse_texts[verse_id]:\n",
    "            verse_texts[verse_id].append(verse_text)\n",
    "\n",
    "    return citations, verse_texts\n",
    "\n",
    "\n",
    "def analyse_verses_top():\n",
    "    \"\"\" Here we count only with filtered stop-subs and resolved multiple attributions. \"\"\"\n",
    "    citations, verse_texts = ciation_counts_per_verses_for_top('MUTUAL_DROP_SURE_MA_DUPS_ST_SUBS_FILTERED_UNFILTERED_batch_results.csv')\n",
    "\n",
    "    citation_counts = []\n",
    "    for verse_id in citations:\n",
    "        citation_counts.append(citations[verse_id])\n",
    "\n",
    "    citation_counts.sort(reverse=True)    \n",
    "\n",
    "    out_df_dict = {'verse': [], 'citation count': [], 'verse texts': [], 'filter row': []}\n",
    "\n",
    "    for verse_id in citations:\n",
    "        if citations[verse_id] in citation_counts[:10]:\n",
    "            out_df_dict['verse'].append(verse_id)\n",
    "            out_df_dict['citation count'].append(citations[verse_id])\n",
    "            out_df_dict['verse texts'].append(verse_texts[verse_id])\n",
    "            out_df_dict['filter row'].append('top 10')\n",
    "        elif citations[verse_id] in citation_counts[10:20]:\n",
    "            out_df_dict['verse'].append(verse_id)\n",
    "            out_df_dict['citation count'].append(citations[verse_id])\n",
    "            out_df_dict['verse texts'].append(verse_texts[verse_id])\n",
    "            out_df_dict['filter row'].append('top 20')\n",
    "        elif citations[verse_id] in citation_counts[20:30]:\n",
    "            out_df_dict['verse'].append(verse_id)\n",
    "            out_df_dict['citation count'].append(citations[verse_id])\n",
    "            out_df_dict['verse texts'].append(verse_texts[verse_id])\n",
    "            out_df_dict['filter row'].append('top 30')\n",
    "        else:\n",
    "            out_df_dict['verse'].append(verse_id)\n",
    "            out_df_dict['citation count'].append(citations[verse_id])\n",
    "            out_df_dict['verse texts'].append(verse_texts[verse_id])\n",
    "            out_df_dict['filter row'].append('low')\n",
    "\n",
    "\n",
    "    stats_df = pd.DataFrame(out_df_dict)\n",
    "    stats_df.to_csv(os.path.join(RESULTS_PATH, 'statistics', 'top_verse_results_stats.csv'))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyse_verses_top()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top citations - to plot in years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_top_x_verse_ids(x:int, results_filename:str):\n",
    "    \"\"\" This function returns top x citations from results dataframe. \"\"\"\n",
    "\n",
    "    citations, verse_texts = ciation_counts_per_verses_for_top(results_filename)\n",
    "\n",
    "    citation_counts = []\n",
    "    for verse_id in citations:\n",
    "        citation_counts.append(citations[verse_id])\n",
    "\n",
    "    citation_counts.sort(reverse=True)\n",
    "\n",
    "    top_verses = []\n",
    "\n",
    "    for verse_id in citations:\n",
    "        if citations[verse_id] in citation_counts[:x]:\n",
    "            top_verses.append(verse_id)\n",
    "\n",
    "    return top_verses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ciation_counts_per_verses_in_years(results_filename:str, verese_ids_to_plot:list, csv_delimiter=';'):\n",
    "    citations_dataframe = pd.read_csv(os.path.join(RESULTS_PATH, results_filename), quotechar='\"', delimiter=csv_delimiter, encoding='utf-8', index_col=0)\n",
    "\n",
    "    citations = defaultdict(dict)\n",
    "    \n",
    "    for row_id in citations_dataframe.index:\n",
    "        row_dict = citations_dataframe.loc[row_id].to_dict()\n",
    "        year = row_dict['date'].split('.')[-1]\n",
    "        verse_id = row_dict['verse_id']\n",
    "        if verse_id in verese_ids_to_plot:\n",
    "            try:\n",
    "                citations[year][verse_id] += 1\n",
    "            except KeyError:\n",
    "                citations[year][verse_id] = 1\n",
    "\n",
    "    return citations\n",
    "\n",
    "\n",
    "def ciation_counts_per_verses_in_years_drop(results_filename:str, verese_ids_to_plot:list, csv_delimiter=';'):\n",
    "    citations_dataframe = pd.read_csv(os.path.join(RESULTS_PATH, results_filename), quotechar='\"', delimiter=csv_delimiter, encoding='utf-8', index_col=0)\n",
    "    \n",
    "    citations_dataframe = citations_dataframe[citations_dataframe['drop?'] == False]\n",
    "    \n",
    "    citations = defaultdict(dict)\n",
    "    \n",
    "    for row_id in citations_dataframe.index:\n",
    "        row_dict = citations_dataframe.loc[row_id].to_dict()\n",
    "        year = row_dict['date'].split('.')[-1]\n",
    "        verse_id = row_dict['verse_id']\n",
    "        if verse_id in verese_ids_to_plot:\n",
    "            try:\n",
    "                citations[year][verse_id] += 1\n",
    "            except KeyError:\n",
    "                citations[year][verse_id] = 1\n",
    "\n",
    "    return citations\n",
    "\n",
    "\n",
    "def ciation_counts_per_verses_in_years_sure(results_filename:str, verese_ids_to_plot:list, csv_delimiter=';'):\n",
    "    citations_dataframe = pd.read_csv(os.path.join(RESULTS_PATH, results_filename), quotechar='\"', delimiter=csv_delimiter, encoding='utf-8', index_col=0)\n",
    "    \n",
    "    citations_dataframe = citations_dataframe[citations_dataframe['drop?'] == False]\n",
    "    citations_dataframe = citations_dataframe[citations_dataframe['CITATION'] == True]\n",
    "\n",
    "    citations = defaultdict(dict)\n",
    "    \n",
    "    for row_id in citations_dataframe.index:\n",
    "        row_dict = citations_dataframe.loc[row_id].to_dict()\n",
    "        year = row_dict['date'].split('.')[-1]\n",
    "        verse_id = row_dict['verse_id']\n",
    "        if verse_id in verese_ids_to_plot:\n",
    "            try:\n",
    "                citations[year][verse_id] += 1\n",
    "            except KeyError:\n",
    "                citations[year][verse_id] = 1\n",
    "\n",
    "\n",
    "def analyse_verse_ids_counts_in_years(top_x:int):\n",
    "    verese_ids_to_plot = return_top_x_verse_ids(x=top_x, results_filename='MUTUAL_DROP_SURE_MA_DUPS_ST_SUBS_FILTERED_UNFILTERED_batch_results.csv')\n",
    "\n",
    "    citations = ciation_counts_per_verses_in_years_drop('MUTUAL_DROP_SURE_MA_DUPS_ST_SUBS_FILTERED_UNFILTERED_batch_results.csv', verese_ids_to_plot)\n",
    "\n",
    "    out_df_dict = defaultdict(list)\n",
    "\n",
    "    for year in citations:\n",
    "        out_df_dict['year'].append(year)\n",
    "        for verse_id in verese_ids_to_plot:\n",
    "            try:\n",
    "                out_df_dict[verse_id].append(citations[year][verse_id])\n",
    "            except:\n",
    "                out_df_dict[verse_id].append(0)\n",
    "\n",
    "    stats_df = pd.DataFrame(out_df_dict)\n",
    "    stats_df.to_csv(os.path.join(RESULTS_PATH, 'statistics', 'verses_in_years_results_stats.csv'))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyse_verse_ids_counts_in_years(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subset statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Defining subsets books\"\"\"\n",
    "old_testament_books = ['1Kr', '1Pa', '1S', '2Kr', '2Pa', '2S', 'Abd', 'Abk', 'Ag', 'Am', 'Da', 'Dt', 'Est', 'Ex', 'Ez', 'Ezd', 'Gn', 'Iz', 'Jb', 'Jl', 'Jon', 'Joz', 'Jr', 'Kaz', 'Lv', 'Mal', 'Mi', 'Na', 'Neh', 'Nu', 'Oz', 'Pis', 'Pl', 'Pr', 'Rt', 'Sd', 'Sf', 'Z', 'Za']\n",
    "deuterocanoncal_books = ['1Ma', '2Ma', 'Bar', 'Jud', 'Mou', 'Sir', 'Tob', 'Zuz']\n",
    "gospels = ['Mk', 'Mt', 'L', 'J']\n",
    "new_testament_books_no_gospels = ['1J', '1K', '1P', '1Te', '1Tm', '2J', '2K', '2P', '2Te', '2Tm', '3J', 'Ef', 'Fm', 'Fp', 'Ga', 'Jk', 'Ju', 'Ko', 'R', 'Sk', 'Tit', 'Zd', 'Zj']\n",
    "new_testament_books = ['1J', '1K', '1P', '1Te', '1Tm', '2J', '2K', '2P', '2Te', '2Tm', '3J', 'Ef', 'Fm', 'Fp', 'Ga', 'Jk', 'Ju', 'Ko', 'R', 'Sk', 'Tit', 'Zd', 'Zj', 'Mk', 'Mt', 'L', 'J']\n",
    "\n",
    "\"\"\" Defining subsets verses\"\"\"\n",
    "ten_commandments_verses = ['Ex 20:2', 'Ex 20:3', 'Ex 20:4', 'Ex 20:5', 'Ex 20:6', 'Ex 20:7', 'Ex 20:8', 'Ex 20:9', 'Ex 20:10', 'Ex 20:11', 'Ex 20:12', 'Ex 20:13', 'Ex 20:14', 'Ex 20:15', 'Ex 20:16', 'Ex 20:17', 'Dt 5:6', 'Dt 5:7', 'Dt 5:8', 'Dt 5:9', 'Dt 5:10', 'Dt 5:11', 'Dt 5:12', 'Dt 5:13', 'Dt 5:14', 'Dt 5:15', 'Dt 5:16', 'Dt 5:17', 'Dt 5:18', 'Dt 5:19', 'Dt 5:20', 'Dt 5:21']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_book_name(verse_id:str):\n",
    "    return verse_id.split(' ')[0]\n",
    "\n",
    "\n",
    "def return_top_x_verse_ids_in_subset_books(x:int, results_filename:str, subset_books:list):\n",
    "    \"\"\" This function returns top x citations from results dataframe. \"\"\"\n",
    "\n",
    "    citations, verse_texts = ciation_counts_per_verses_for_top(results_filename)\n",
    "\n",
    "    citation_counts = []\n",
    "    verses_in_book = []\n",
    "    for verse_id in citations:\n",
    "        if '/'in verse_id:\n",
    "            shared_verse_ids = verse_id.split('/')\n",
    "            is_in_subset = False\n",
    "            for shared_verse in shared_verse_ids:\n",
    "                book_name = get_book_name(shared_verse)\n",
    "                if book_name in subset_books:\n",
    "                    citation_counts.append(citations[verse_id])\n",
    "                    verses_in_book.append(verse_id)\n",
    "                    break\n",
    "        else:\n",
    "            book_name = get_book_name(verse_id)\n",
    "            if book_name in subset_books:\n",
    "                citation_counts.append(citations[verse_id])\n",
    "                verses_in_book.append(verse_id)\n",
    "\n",
    "    citation_counts.sort(reverse=True)\n",
    "\n",
    "    top_verses = []\n",
    "\n",
    "    for verse_id in verses_in_book:\n",
    "        if citations[verse_id] in citation_counts[:x]:\n",
    "            top_verses.append(verse_id)\n",
    "\n",
    "    return top_verses\n",
    "\n",
    "\n",
    "def ciation_counts_per_verses_in_years_subset_verses(results_filename:str, verse_ids_to_plot:list, csv_delimiter=';', plot_shared=False):\n",
    "    print(verse_ids_to_plot)\n",
    "    citations_dataframe = pd.read_csv(os.path.join(RESULTS_PATH, results_filename), quotechar='\"', delimiter=csv_delimiter, encoding='utf-8', index_col=0)\n",
    "    \n",
    "    citations_dataframe = citations_dataframe[citations_dataframe['drop?'] == False]\n",
    "\n",
    "    citations = defaultdict(dict)\n",
    "\n",
    "    plotted_verses = []\n",
    "\n",
    "    if plot_shared:\n",
    "        for row_id in citations_dataframe.index:\n",
    "            row_dict = citations_dataframe.loc[row_id].to_dict()\n",
    "            year = row_dict['date'].split('.')[-1]\n",
    "            verse_id = row_dict['verse_id']\n",
    "\n",
    "            if verse_id in verse_ids_to_plot:\n",
    "                if verse_id not in plotted_verses:\n",
    "                    plotted_verses.append(verse_id)\n",
    "                try:\n",
    "                    citations[year][verse_id] += 1\n",
    "                except KeyError:\n",
    "                    citations[year][verse_id] = 1\n",
    "            \n",
    "            else:\n",
    "                if '/' in verse_id:\n",
    "                    shared_vereses = verse_id.split('/')\n",
    "                    plot = False\n",
    "                    for shared_verse in shared_vereses:\n",
    "                        if shared_verse in verse_ids_to_plot:\n",
    "                            plot = True\n",
    "                            break\n",
    "                    if plot:\n",
    "                        if verse_id not in plotted_verses:\n",
    "                            plotted_verses.append(verse_id)\n",
    "                        try:\n",
    "                            citations[year][verse_id] += 1\n",
    "                        except KeyError:\n",
    "                            citations[year][verse_id] = 1\n",
    "    \n",
    "    else:\n",
    "        for row_id in citations_dataframe.index:\n",
    "            row_dict = citations_dataframe.loc[row_id].to_dict()\n",
    "            year = row_dict['date'].split('.')[-1]\n",
    "            verse_id = row_dict['verse_id']\n",
    "\n",
    "            if verse_id in verse_ids_to_plot:\n",
    "                if verse_id not in plotted_verses:\n",
    "                    plotted_verses.append(verse_id)\n",
    "                try:\n",
    "                    citations[year][verse_id] += 1\n",
    "                except KeyError:\n",
    "                    citations[year][verse_id] = 1\n",
    "\n",
    "    return citations, plotted_verses\n",
    "\n",
    "\n",
    "def subset_statistics_books(top_x:int, subset_books:list, resulst_prefix_name:str):\n",
    "    verese_ids_to_plot = return_top_x_verse_ids_in_subset_books(x=top_x, results_filename='MUTUAL_DROP_SURE_MA_DUPS_ST_SUBS_FILTERED_UNFILTERED_batch_results.csv', subset_books=subset_books)\n",
    "\n",
    "    citations, plotted_verses = ciation_counts_per_verses_in_years_subset_verses('MUTUAL_DROP_SURE_MA_DUPS_ST_SUBS_FILTERED_UNFILTERED_batch_results.csv', verese_ids_to_plot)\n",
    "\n",
    "    out_df_dict = defaultdict(list)\n",
    "\n",
    "    for year in citations:\n",
    "        out_df_dict['year'].append(year)\n",
    "        for verse_id in plotted_verses:\n",
    "            try:\n",
    "                out_df_dict[verse_id].append(citations[year][verse_id])\n",
    "            except:\n",
    "                out_df_dict[verse_id].append(0)\n",
    "\n",
    "    stats_df = pd.DataFrame(out_df_dict)\n",
    "    stats_df = stats_df.sort_values(by='year')\n",
    "    stats_df.to_csv(os.path.join(RESULTS_PATH, 'statistics', f'{resulst_prefix_name}_books_subset_results_stats.csv'))\n",
    "\n",
    "\n",
    "def subset_statistics_verses(verese_ids_to_plot:list, resulst_prefix_name:str):\n",
    "    citations, plotted_verses = ciation_counts_per_verses_in_years_subset_verses('MUTUAL_DROP_SURE_MA_DUPS_ST_SUBS_FILTERED_UNFILTERED_batch_results.csv', verese_ids_to_plot, plot_shared=True)\n",
    "\n",
    "    print(plotted_verses)\n",
    "\n",
    "    out_df_dict = defaultdict(list)\n",
    "\n",
    "    for year in citations:\n",
    "        out_df_dict['year'].append(year)\n",
    "        for verse_id in plotted_verses:\n",
    "            try:\n",
    "                out_df_dict[verse_id].append(citations[year][verse_id])\n",
    "            except:\n",
    "                out_df_dict[verse_id].append(0)\n",
    "\n",
    "    stats_df = pd.DataFrame(out_df_dict)\n",
    "    stats_df = stats_df.sort_values(by='year')\n",
    "    stats_df.to_csv(os.path.join(RESULTS_PATH, 'statistics', f'{resulst_prefix_name}_verses_subset_results_stats.csv'))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ex 20:2', 'Ex 20:3', 'Ex 20:4', 'Ex 20:5', 'Ex 20:6', 'Ex 20:7', 'Ex 20:8', 'Ex 20:9', 'Ex 20:10', 'Ex 20:11', 'Ex 20:12', 'Ex 20:13', 'Ex 20:14', 'Ex 20:15', 'Ex 20:16', 'Ex 20:17', 'Dt 5:6', 'Dt 5:7', 'Dt 5:8', 'Dt 5:9', 'Dt 5:10', 'Dt 5:11', 'Dt 5:12', 'Dt 5:13', 'Dt 5:14', 'Dt 5:15', 'Dt 5:16', 'Dt 5:17', 'Dt 5:18', 'Dt 5:19', 'Dt 5:20', 'Dt 5:21']\n",
      "['Ex 20:13/Dt 5:17', 'Ex 20:2/Dt 5:6', 'Ex 20:5', 'Ex 20:15/Dt 5:19', 'Ex 20:12/Dt 5:16/Ef 6:2', 'Ex 20:3/Dt 5:7', 'Ex 20:14/Dt 5:18', 'Dt 5:21', 'Ex 20:16/Dt 5:20', 'Dt 5:9', 'Ex 20:8']\n"
     ]
    }
   ],
   "source": [
    "subset_statistics_verses(verese_ids_to_plot=ten_commandments_verses, resulst_prefix_name='ten_commandments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mt 3:3/J 1:23/Mk 1:3/Iz 40:3', 'Ex 20:13/Dt 5:17', 'Ex 20:15/Dt 5:19', 'Z 127:1', 'Ex 20:12/Dt 5:16/Ef 6:2', 'Gn 3:19', 'Pr 26:27', '2S 14:5', 'Ex 20:14/Dt 5:18', 'Iz 45:8', 'Pr 31:10', 'Ez 24:19']\n",
      "['Mt 5:38', 'L 3:4', 'Mt 3:3/J 1:23/Mk 1:3/Iz 40:3', 'L 2:14', 'Mt 11:28', 'Mt 6:11/L 11:3', 'Ex 20:12/Dt 5:16/Ef 6:2', 'Mt 16:18', 'L 20:25', 'Mt 20:16']\n",
      "['1J 5:6', 'R 13:11', 'Sk 5:29', '2P 1:17', 'Ex 20:12/Dt 5:16/Ef 6:2', '2K 1:2/Fp 1:2/2Te 1:2/1K 1:3/Ef 1:2/Ga 1:3', '1K 15:20', '2Tm 4:7', 'Zd 5:9', 'Sk 2:17', '2K 2:6', '2K 7:10']\n",
      "['Mt 5:38', 'L 3:4', 'Mt 3:3/J 1:23/Mk 1:3/Iz 40:3', 'L 2:14', 'Mt 11:28', 'Mt 6:11/L 11:3', 'Mt 27:25', 'Mt 16:18', 'L 18:42', 'L 20:25', 'Mt 20:16']\n",
      "['2Ma 14:25', 'Tob 5:11', 'Tob 8:10', 'Sir 51:24', 'Sir 10:27', 'Tob 2:13', 'Mou 16:24', '2Ma 14:26', 'Sir 36:12', 'Jud 13:24', 'Jud 13:15', 'Sir 13:8', '2Ma 2:6', 'Sir 19:22', 'Zuz 1:46', 'Sir 35:21', '2Ma 4:18', 'Sir 33:15', 'Mou 19:4']\n",
      "['Ex 20:2', 'Ex 20:3', 'Ex 20:4', 'Ex 20:5', 'Ex 20:6', 'Ex 20:7', 'Ex 20:8', 'Ex 20:9', 'Ex 20:10', 'Ex 20:11', 'Ex 20:12', 'Ex 20:13', 'Ex 20:14', 'Ex 20:15', 'Ex 20:16', 'Ex 20:17', 'Dt 5:6', 'Dt 5:7', 'Dt 5:8', 'Dt 5:9', 'Dt 5:10', 'Dt 5:11', 'Dt 5:12', 'Dt 5:13', 'Dt 5:14', 'Dt 5:15', 'Dt 5:16', 'Dt 5:17', 'Dt 5:18', 'Dt 5:19', 'Dt 5:20', 'Dt 5:21']\n"
     ]
    }
   ],
   "source": [
    "subset_statistics_books(top_x=10, subset_books=old_testament_books, resulst_prefix_name='old_testament')\n",
    "subset_statistics_books(top_x=10, subset_books=new_testament_books, resulst_prefix_name='new_testament')\n",
    "subset_statistics_books(top_x=10, subset_books=new_testament_books_no_gospels, resulst_prefix_name='new_testament_no_gospels')\n",
    "subset_statistics_books(top_x=10, subset_books=gospels, resulst_prefix_name='gospels')\n",
    "subset_statistics_books(top_x=10, subset_books=deuterocanoncal_books, resulst_prefix_name='deuterocanonical')\n",
    "subset_statistics_verses(verese_ids_to_plot=ten_commandments_verses, resulst_prefix_name='ten_commandments')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map of meanings\n",
    "The following functions are used to create a network chart that shows how individual journals are connected with themselves through the citations of same verses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_verse_group(verse_id:str):\n",
    "    \"\"\" This function returns the group of Biblical texts to which the verse belongs. \"\"\"\n",
    "    if verse_id.split('/')[0] in ten_commandments_verses or verse_id in ten_commandments_verses:\n",
    "        return 'Desatero'\n",
    "    \n",
    "    else:\n",
    "        book_id = get_book_name(verse_id)\n",
    "        if book_id in old_testament_books:\n",
    "            return 'Starý zákon'\n",
    "        elif book_id in gospels:\n",
    "            return 'Evangelia'\n",
    "        elif book_id in new_testament_books_no_gospels:\n",
    "            return 'Nový zákon'\n",
    "        elif book_id in deuterocanoncal_books:\n",
    "            return 'Deuterokanonické knihy'\n",
    "        else:\n",
    "            return 'neklasifikováno'\n",
    "    \n",
    "\n",
    "def network_graph_creation(results_filename='MUTUAL_DROP_SURE_MA_DUPS_ST_SUBS_FILTERED_UNFILTERED_batch_results.csv', value_treshold=3, csv_delimiter=';', out_filename='map_of_meanings.csv'):\n",
    "    \"\"\" This functions creates datafiles for network grpahs - map_of_meanings.csv (= file with links from journal to verse) and map_of_meanings_points.csv (metadata for points). \n",
    "    \n",
    "    :param value_treshold: how many citations must there be, to consider the point in the dataset\n",
    "    \"\"\"\n",
    "    citations_dataframe = pd.read_csv(os.path.join(RESULTS_PATH, results_filename), quotechar='\"', delimiter=csv_delimiter, encoding='utf-8', index_col=0)\n",
    "    \n",
    "    citations_dataframe = citations_dataframe[citations_dataframe['drop?'] == False]\n",
    "\n",
    "    points_dict = {}\n",
    "    for journal in all_journals:\n",
    "        points_dict[journal] = {'size': 5, 'Group': journal, 'Verse text': journal}\n",
    "\n",
    "\n",
    "    out_df_dict_collect = {}\n",
    "    out_idx = 0\n",
    "\n",
    "    for row_id in citations_dataframe.index:\n",
    "        row_dict = citations_dataframe.loc[row_id].to_dict()\n",
    "        verse_id = row_dict['verse_id']\n",
    "        journal = row_dict['journal']\n",
    "        year = row_dict['date'].split('.')[-1]\n",
    "        verse_text = row_dict['verse_text']\n",
    "\n",
    "        if verse_id not in points_dict:\n",
    "            group = get_verse_group(verse_id)\n",
    "            points_dict[verse_id] = {'size': 1, 'Group': group, 'Verse text': verse_text}\n",
    "\n",
    "        out_df_dict_collect[out_idx] = {'Source': journal, 'Target': verse_id}\n",
    "        out_idx += 1\n",
    "    \n",
    "    values_dict ={}\n",
    "    for idx in out_df_dict_collect:\n",
    "        source = out_df_dict_collect[idx]['Source']\n",
    "        target = out_df_dict_collect[idx]['Target']\n",
    "        row_name = f'{source} {target}'\n",
    "        if row_name in values_dict:\n",
    "            values_dict[row_name]['Value'] += 1\n",
    "        else:\n",
    "            values_dict[row_name] = {'Source': source, 'Target': target, 'Value': 1}\n",
    "\n",
    "    out_df_dict = {}\n",
    "    out_points_dict = {}\n",
    "    row_id = 0\n",
    "    for row_name in values_dict:\n",
    "        if values_dict[row_name]['Value'] >= value_treshold:\n",
    "            out_df_dict[row_id] = values_dict[row_name]\n",
    "            row_id += 1\n",
    "            if values_dict[row_name]['Target'] not in out_points_dict:\n",
    "                out_points_dict[values_dict[row_name]['Target']] = points_dict[values_dict[row_name]['Target']]\n",
    "    \n",
    "    for journal in all_journals:\n",
    "        out_points_dict[journal] = {'size': 5, 'Group': f'Periodikum: {journal}', 'Verse text': journal}\n",
    "    \n",
    "    output_df = pd.DataFrame.from_dict(out_df_dict)\n",
    "    output_df = output_df.transpose()\n",
    "\n",
    "    output_df.to_csv(os.path.join(RESULTS_PATH, 'statistics', out_filename), quotechar='\"', sep=',', encoding='utf-8')\n",
    "\n",
    "    output_df_points = pd.DataFrame.from_dict(out_points_dict)\n",
    "    output_df_points = output_df_points.transpose()\n",
    "\n",
    "    output_df_points.to_csv(os.path.join(RESULTS_PATH, 'statistics', f'{out_filename[:-4]}_points.csv'), quotechar='\"', sep=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_graph_creation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other versions of the map of meanings\n",
    "##### 1) show only those points that connect two or more journals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_verses_shared_by_journals(map_of_meanings_data='map_of_meanings.csv', points_data='map_of_meanings_points.csv', csv_delimiter=','):\n",
    "    \"\"\" This function prepares the map of meanings that show only the shared citations. \"\"\"\n",
    "    map_of_meanings_dataset = pd.read_csv(os.path.join(RESULTS_PATH, 'statistics', map_of_meanings_data), quotechar='\"', delimiter=csv_delimiter, encoding='utf-8', index_col=0)\n",
    "\n",
    "    points_dataset = pd.read_csv(os.path.join(RESULTS_PATH, 'statistics', points_data), quotechar='\"', delimiter=csv_delimiter, encoding='utf-8', index_col=0)\n",
    "\n",
    "    verse_counts = map_of_meanings_dataset.Target.value_counts()\n",
    "\n",
    "    out_df_dict = {}\n",
    "    row_id = 0\n",
    "\n",
    "    for row_id in map_of_meanings_dataset.index:\n",
    "        row_data = map_of_meanings_dataset.loc[row_id].to_dict()\n",
    "        verse_id = row_data['Target']\n",
    "        if verse_counts[verse_id] >= 2:\n",
    "            out_df_dict[row_id] = row_data\n",
    "            row_id += 1\n",
    "        else:\n",
    "            points_dataset = points_dataset.drop(verse_id)\n",
    "\n",
    "    output_df = pd.DataFrame.from_dict(out_df_dict)\n",
    "    output_df = output_df.transpose()\n",
    "\n",
    "    output_df.to_csv(os.path.join(RESULTS_PATH, 'statistics', f'shared_{map_of_meanings_data}'), quotechar='\"', sep=',', encoding='utf-8')\n",
    "\n",
    "    points_dataset.to_csv(os.path.join(RESULTS_PATH, 'statistics', f'shared_{map_of_meanings_data[:-4]}_points.csv'), quotechar='\"', sep=',', encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_graph_creation(out_filename='map_of_meanings_treshold_1.csv', value_treshold=1)\n",
    "select_verses_shared_by_journals(map_of_meanings_input='map_of_meanings_treshold_1.csv', points_data='map_of_meanings_treshold_1_points.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) filtering based on: appears at least 3-5x, 6-10x, 11-15x, 16-20x, 20+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_of_meanings_by_citation_count(map_of_meanings_data='map_of_meanings_treshold_1.csv', points_data='map_of_meanings_treshold_1_points.csv', csv_delimiter=','):\n",
    "    \"\"\" This function prepares the map of meanings that prapares the map of meanings that is filterable by how many times a verse citation appears. \"\"\"\n",
    "    map_of_meanings_dataset = pd.read_csv(os.path.join(RESULTS_PATH, 'statistics', map_of_meanings_data), quotechar='\"', delimiter=csv_delimiter, encoding='utf-8', index_col=0)\n",
    "\n",
    "    points_dataset = pd.read_csv(os.path.join(RESULTS_PATH, 'statistics', points_data), quotechar='\"', delimiter=csv_delimiter, encoding='utf-8', index_col=0)\n",
    "\n",
    "    points_groups = ['3-5', '6-10', '11-15', '16-20', '21+']\n",
    "\n",
    "    out_points_dict = {}\n",
    "\n",
    "    for row_id in points_dataset.index:\n",
    "        row_data = points_dataset.loc[row_id].to_dict()\n",
    "        # NOTE: verse points have size 1 in the points dataset\n",
    "        if row_data['size'] == 1:\n",
    "            # NOTE: row_id = verse_id\n",
    "            verse_id_citation_count = 0\n",
    "            subset_df = map_of_meanings_dataset.loc[map_of_meanings_dataset['Target'] == row_id]\n",
    "            for subset_row_id in subset_df.index:\n",
    "                sub_row_data = subset_df.loc[subset_row_id].to_dict()\n",
    "                verse_id_citation_count += sub_row_data['Value']\n",
    "            \n",
    "            if verse_id_citation_count <= 2:\n",
    "                row_data = None\n",
    "            elif verse_id_citation_count <= 5:\n",
    "                row_data['Group'] = '3-5'\n",
    "            elif verse_id_citation_count <= 10:\n",
    "                row_data['Group'] = '6-10'\n",
    "            elif verse_id_citation_count <= 15:\n",
    "                row_data['Group'] = '11-15'\n",
    "            elif verse_id_citation_count <= 20:\n",
    "                row_data['Group'] = '16-20'\n",
    "            else:\n",
    "                row_data['Group'] = '21+'\n",
    "\n",
    "        if row_data:\n",
    "            out_points_dict[row_id] = row_data\n",
    "\n",
    "    output_df = pd.DataFrame.from_dict(out_points_dict)\n",
    "    output_df = output_df.transpose()\n",
    "\n",
    "    output_df.to_csv(os.path.join(RESULTS_PATH, 'statistics', 'by_value_map_of_meanings_points.csv'), quotechar='\"', sep=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_of_meanings_by_citation_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3) connect journals based on how many same verses they cite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_of_meanings_just_journals(map_of_meanings_data='map_of_meanings.csv', points_data='map_of_meanings_points.csv', csv_delimiter=','):\n",
    "    \"\"\" This function prepares the map of meanings that prapares the map of meanings that is filterable by how many times a verse citation appears. \"\"\"\n",
    "    map_of_meanings_dataset = pd.read_csv(os.path.join(RESULTS_PATH, 'statistics', map_of_meanings_data), quotechar='\"', delimiter=csv_delimiter, encoding='utf-8', index_col=0)\n",
    "\n",
    "    points_dataset = pd.read_csv(os.path.join(RESULTS_PATH, 'statistics', points_data), quotechar='\"', delimiter=csv_delimiter, encoding='utf-8', index_col=0)\n",
    "\n",
    "    out_points_dict = {}\n",
    "    out_links_dict = {}\n",
    "    links_row_id = 0\n",
    "\n",
    "    for row_id in points_dataset.index:\n",
    "        row_data = points_dataset.loc[row_id].to_dict()\n",
    "        # NOTE: verse points have size 1 in the points dataset\n",
    "        if row_data['size'] == 1:\n",
    "            # NOTE: row_id = verse_id\n",
    "            verse_id_citation_count = 0\n",
    "            subset_df = map_of_meanings_dataset.loc[map_of_meanings_dataset['Target'] == row_id]\n",
    "            journals_for_this_verse = subset_df['Source'].tolist()\n",
    "            for journal_from in journals_for_this_verse:\n",
    "                reverses_now = []\n",
    "                for journal_to in journals_for_this_verse:\n",
    "                    if journal_from == journal_to:\n",
    "                        continue\n",
    "                    elif f'{journal_to}-{journal_from}' in reverses_now:\n",
    "                        continue\n",
    "                    else:\n",
    "                        if f'{journal_from}-{journal_to}' in out_links_dict:\n",
    "                            out_links_dict[f'{journal_from}-{journal_to}']['Shared'] += 1\n",
    "                        else:\n",
    "                            out_links_dict[f'{journal_from}-{journal_to}'] = {}\n",
    "                            out_links_dict[f'{journal_from}-{journal_to}']['Source'] = journal_from\n",
    "                            out_links_dict[f'{journal_from}-{journal_to}']['Target'] = journal_to\n",
    "                            out_links_dict[f'{journal_from}-{journal_to}']['Shared'] = 1\n",
    "\n",
    "        else:\n",
    "            # NOTE: if the size is not 1 than row_id = journal name\n",
    "            # Here, we set the size of journal points according to their aggregated citation value\n",
    "            verse_id_citation_count = 0\n",
    "            subset_df = map_of_meanings_dataset.loc[map_of_meanings_dataset['Source'] == row_id]\n",
    "            for subset_row_id in subset_df.index:\n",
    "                sub_row_data = subset_df.loc[subset_row_id].to_dict()\n",
    "                #verse_id_citation_count += sub_row_data['Value']\n",
    "                verse_id_citation_count += 1\n",
    "\n",
    "            row_data['size'] = int(verse_id_citation_count)\n",
    "            out_points_dict[row_id] = row_data\n",
    "\n",
    "    for row_id in out_links_dict:\n",
    "        row_data = out_links_dict[row_id]\n",
    "        source = row_data['Source']\n",
    "        target = row_data['Target']  \n",
    "        shared = row_data['Shared']\n",
    "\n",
    "        source_full = out_points_dict[source]['size']\n",
    "        target_full = out_points_dict[target]['size']\n",
    "\n",
    "        proportion = (shared)/(source_full+target_full-shared)\n",
    "        out_links_dict[row_id]['Value'] = proportion\n",
    "\n",
    "    output_df = pd.DataFrame.from_dict(out_links_dict)\n",
    "    output_df = output_df.transpose()\n",
    "\n",
    "    output_df.to_csv(os.path.join(RESULTS_PATH, 'statistics', 'journals_map_of_meanings.csv'), quotechar='\"', sep=',', encoding='utf-8')\n",
    "\n",
    "    output_points_df = pd.DataFrame.from_dict(out_points_dict)\n",
    "    output_points_df = output_points_df.transpose()\n",
    "\n",
    "    output_points_df.to_csv(os.path.join(RESULTS_PATH, 'statistics', 'journals_map_of_meanings_points.csv'), quotechar='\"', sep=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_of_meanings_just_journals(map_of_meanings_data='map_of_meanings_treshold_1.csv', points_data='map_of_meanings_treshold_1_points.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change verse IDs from Czech format to SBL markings.\n",
    "Because we are working with Czech translations of the Bible, we use Czech designation of books and therefore also verses. With the following function, you can change verse IDs in any result CSV file into the SBL-like designation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Define concordances \"\"\"\n",
    "\n",
    "cze_to_sbl_book_ids = {'Gn': 'Gen', 'Ex': 'Exod', 'Lv': 'Lev', 'Nu': 'Num', 'Dt': 'Deut', 'Joz': 'Josh', 'Sd': 'Judg', 'Rt': 'Ruth', '1S': '1Sam', '2S': '2Sam', '1Kr': '1Kgs', '2Kr': '2Kgs', '1Pa': '1Chr', '2Pa': '2Chr', 'Ezd': 'Ezra', 'Neh': 'Neh', 'Est': 'Esth', 'Jb': 'Job', 'Z': 'Ps', 'Pr': 'Prov', 'Kaz': 'Eccl', 'Pis': 'Song', 'Iz': 'Isa', 'Jr': 'Jer', 'Pl': 'Lam', 'Ez': 'Ezek', 'Da': 'Dan', 'Oz': 'Hos', 'Jl': 'Joel', 'Am': 'Amos', 'Abd': 'Obad', 'Jon': 'Jonah', 'Mi': 'Mic', 'Na': 'Nah', 'Abk': 'Hab', 'Sf': 'Zeph', 'Ag': 'Hag', 'Za': 'Zech', 'Mal': 'Mal', 'Tob': 'Tob', 'Jud': 'Jdt', 'Mou': 'Wis', 'Sir': 'Sir', 'Bar': 'Bar', '1Ma': '1Macc', '2Ma': '2Macc', 'Mt': 'Matt', 'Mk': 'Mark', 'L': 'Luke', 'J': 'John', 'Sk': 'Acts', 'R': 'Rom', '1K': '1Cor', '2K': '2Cor', 'Ga': 'Gal', 'Ef': 'Eph', 'Fp': 'Phil', 'Ko': 'Col', '1Te': '1Thess', '2Te': '2Thess', '1Tm': '1Tim', '2Tm': '2Tim', 'Tit': 'Titus', 'Fm': 'Phlm', 'Zd': 'Heb', 'Jk': 'Jas', '1P': '1Pet', '2P': '2Pet', '1J': '1John', '2J': '2John', '3J': '3John', 'Ju': 'Jude', 'Zj': 'Rev', 'Zuz': 'Sus'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_verse_ids_in_csv_columns(path_to_csv_file:str, csv_delimiter=',', verse_column_name='verse_id'):\n",
    "    \"\"\" This function changes verse IDs from the Czech format to the SBL one. The input file must be CSV file with one column that includes verse IDs. It is then saved with preposition SBL_.\n",
    "    :param verse_column_name: if the verse IDs are the index of the datarframe, set 0 \"\"\"\n",
    "    input_df = pd.read_csv(path_to_csv_file, quotechar='\"', delimiter=csv_delimiter, encoding='utf-8', index_col=0)\n",
    "    original_df = input_df.copy()\n",
    "\n",
    "    if verse_column_name == 0:\n",
    "        for row_id in input_df.index:\n",
    "            verse_ids = row_id\n",
    "            if ':' in verse_ids:\n",
    "                verses_in_line = verse_ids.split('/')\n",
    "                new_verse_id = ''\n",
    "                for verse_id in verses_in_line:\n",
    "                    book_name = verse_id.split(' ')[0]\n",
    "                    new_verse_id_instance = verse_id.replace(book_name, cze_to_sbl_book_ids[book_name])\n",
    "                    if new_verse_id == '':\n",
    "                        new_verse_id = new_verse_id_instance\n",
    "                    else:\n",
    "                        new_verse_id += f'/{new_verse_id_instance}'\n",
    "                input_df = input_df.rename({row_id: new_verse_id}, axis='index')\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "    else:\n",
    "        for row_id in input_df.index:\n",
    "            verse_ids = input_df.loc[row_id][verse_column_name]\n",
    "            if ':' in verse_ids:\n",
    "                verses_in_line = verse_ids.split('/')\n",
    "                new_verse_id = ''\n",
    "                for verse_id in verses_in_line:\n",
    "                    book_name = verse_id.split(' ')[0]\n",
    "                    new_verse_id_instance = verse_id.replace(book_name, cze_to_sbl_book_ids[book_name])\n",
    "                    if new_verse_id == '':\n",
    "                        new_verse_id = new_verse_id_instance\n",
    "                    else:\n",
    "                        new_verse_id += f'/{new_verse_id_instance}'\n",
    "                input_df.at[row_id, verse_column_name] = new_verse_id\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "    # Check if there have been any changes and if so, save the new df\n",
    "    if original_df.equals(input_df):\n",
    "        original_filename = os.path.basename(path_to_csv_file)\n",
    "        print(original_filename, 'has not changed')\n",
    "        return\n",
    "    else:\n",
    "        original_filename = os.path.basename(path_to_csv_file)\n",
    "        dir_csv = os.path.dirname(path_to_csv_file)\n",
    "        input_df.to_csv(os.path.join(dir_csv, f'SBL_{original_filename}'), quotechar='\"', sep=',', encoding='utf-8')\n",
    "        print(f'SBL_{original_filename}', 'has been created')\n",
    "\n",
    "\n",
    "def change_verse_ids_in_csv_header(path_to_csv_file:str, csv_delimiter=','):\n",
    "    \"\"\" This function changes the verse IDs from the Czech format to the SBL-like format. This function is made for those dataframes that have the verse IDs as their column header. \"\"\"\n",
    "    input_df = pd.read_csv(path_to_csv_file, quotechar='\"', delimiter=csv_delimiter, encoding='utf-8', index_col=0)\n",
    "    original_df = input_df.copy()\n",
    "\n",
    "    column_names = list(input_df.columns)\n",
    "\n",
    "    for column in column_names:\n",
    "        # just check if the column name has \":\" in it - it means that it is a verse ID and not some other data\n",
    "        if ':' in column:\n",
    "            verses_in_line = column.split('/')\n",
    "            new_verse_id = ''\n",
    "            for verse_id in verses_in_line:\n",
    "                book_name = verse_id.split(' ')[0]\n",
    "                new_verse_id_instance = verse_id.replace(book_name, cze_to_sbl_book_ids[book_name])\n",
    "                if new_verse_id == '':\n",
    "                    new_verse_id = new_verse_id_instance\n",
    "                else:\n",
    "                    new_verse_id += f'/{new_verse_id_instance}'\n",
    "            input_df = input_df.rename({column: new_verse_id}, axis=1)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    # Check if there have been any changes and if so, save the new df\n",
    "    if original_df.equals(input_df):\n",
    "        original_filename = os.path.basename(path_to_csv_file)\n",
    "        print(original_filename, 'has not changed')\n",
    "        return\n",
    "    else:\n",
    "        original_filename = os.path.basename(path_to_csv_file)\n",
    "        dir_csv = os.path.dirname(path_to_csv_file)\n",
    "        input_df.to_csv(os.path.join(dir_csv, f'SBL_{original_filename}'), quotechar='\"', sep=',', encoding='utf-8')\n",
    "        print(f'SBL_{original_filename}', 'has been created')\n",
    "\n",
    "\n",
    "def change_all_statistics_to_SBL(input_directory=os.path.join(RESULTS_PATH, 'statistics')):\n",
    "    \"\"\" This function changes all statistical results created with the functions in this notebook from the Czech format of verse IDs to the SBL-like format. \"\"\"\n",
    "    all_statistics_csvs = os.listdir(input_directory)\n",
    "\n",
    "    colum_names_as_verse_ids = ['verse', 'verse_id', 'Target']\n",
    "\n",
    "    for stats_csv in all_statistics_csvs:\n",
    "        csv_path = os.path.join(input_directory, stats_csv)\n",
    "        if 'SBL' in stats_csv:\n",
    "            continue\n",
    "        elif 'points' in stats_csv:\n",
    "            change_verse_ids_in_csv_columns(csv_path, verse_column_name=0)\n",
    "        else:\n",
    "            input_df = pd.read_csv(os.path.join(input_directory, stats_csv), quotechar='\"', delimiter=',', encoding='utf-8', index_col=0)\n",
    "            column_names = list(input_df.columns)\n",
    "            change_colums = False\n",
    "            for column in column_names:\n",
    "                if column in colum_names_as_verse_ids:\n",
    "                    change_colums = True\n",
    "                    break\n",
    "            \n",
    "            if change_colums:\n",
    "                change_verse_ids_in_csv_columns(path_to_csv_file=csv_path, verse_column_name=column)\n",
    "            else:\n",
    "                change_verse_ids_in_csv_header(path_to_csv_file=csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bible_stats.csv has not changed\n",
      "SBL_by_value_map_of_meanings_points.csv has been created\n",
      "SBL_deuterocanonical_books_subset_results_stats.csv has been created\n",
      "SBL_gospels_books_subset_results_stats.csv has been created\n",
      "journals_map_of_meanings.csv has not changed\n",
      "journals_map_of_meanings_points.csv has not changed\n",
      "journals_results_stats.csv has not changed\n",
      "journals_stats.csv has not changed\n",
      "SBL_map_of_meanings.csv has been created\n",
      "SBL_map_of_meanings_points.csv has been created\n",
      "SBL_map_of_meanings_treshold_1.csv has been created\n",
      "SBL_map_of_meanings_treshold_1_points.csv has been created\n",
      "SBL_new_testament_books_subset_results_stats.csv has been created\n",
      "SBL_new_testament_no_gospels_books_subset_results_stats.csv has been created\n",
      "SBL_old_testament_books_subset_results_stats.csv has been created\n",
      "runtimes_stats.csv has not changed\n",
      "SBL_shared_map_of_meanings_treshold_1.csv has been created\n",
      "SBL_shared_map_of_meanings_treshold_1_points.csv has been created\n",
      "SBL_ten_commandments_verses_subset_results_stats.csv has been created\n",
      "SBL_top_verse_results_stats.csv has been created\n",
      "SBL_verses_in_years_results_stats.csv has been created\n",
      "SBL_verse_results_stats.csv has been created\n",
      "years_results_stats.csv has not changed\n"
     ]
    }
   ],
   "source": [
    "change_all_statistics_to_SBL()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FULL results stats creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered citations:\n",
      "Total number of citations: 38039\n",
      "Moravský hospodář 285\n",
      "Polední list 2334\n",
      "Moravský večerník 4406\n",
      "Věstník katolického duchovenstva 2008\n",
      "Přítomnost 2205\n",
      "Venkov 14309\n",
      "Studentský časopis 506\n",
      "Československý zemědělec 1154\n",
      "Český učitel 1110\n",
      "Čech 8277\n",
      "Posel záhrobní 1445\n",
      "\n",
      "Stop subs:\n",
      "Total number of citations: 12137\n",
      "Moravský hospodář 4\n",
      "Polední list 209\n",
      "Moravský večerník 599\n",
      "Věstník katolického duchovenstva 1529\n",
      "Přítomnost 559\n",
      "Venkov 2212\n",
      "Studentský časopis 159\n",
      "Československý zemědělec 206\n",
      "Český učitel 386\n",
      "Čech 5237\n",
      "Posel záhrobní 1037\n",
      "\n",
      "Multiple attrs:\n",
      "Total number of citations: 7103\n",
      "Moravský hospodář 2\n",
      "Polední list 147\n",
      "Moravský večerník 381\n",
      "Věstník katolického duchovenstva 772\n",
      "Přítomnost 342\n",
      "Venkov 1528\n",
      "Studentský časopis 102\n",
      "Československý zemědělec 127\n",
      "Český učitel 225\n",
      "Čech 3022\n",
      "Posel záhrobní 455\n",
      "\n",
      "\"Sure\" citations:\n",
      "Total number of citations: 1239\n",
      "Moravský hospodář 0\n",
      "Polední list 17\n",
      "Moravský večerník 35\n",
      "Věstník katolického duchovenstva 219\n",
      "Přítomnost 53\n",
      "Venkov 180\n",
      "Studentský časopis 16\n",
      "Československý zemědělec 31\n",
      "Český učitel 39\n",
      "Čech 496\n",
      "Posel záhrobní 153\n",
      "Filtered citations:\n",
      "defaultdict(<class 'int'>, {'1927': 3276, '1926': 2687, '1929': 2613, '1928': 2554, '1930': 2899, '1925': 3103, '1934': 2192, '1931': 3127, '1933': 3059, '1932': 2510, '1935': 2027, '1938': 1946, '1937': 2085, '1936': 2067, '1939': 1894})\n",
      "\n",
      "Stop subs:\n",
      "defaultdict(<class 'int'>, {'1927': 1336, '1926': 941, '1928': 828, '1930': 893, '1925': 1380, '1934': 827, '1933': 717, '1932': 699, '1929': 874, '1931': 1144, '1935': 577, '1938': 444, '1936': 481, '1939': 479, '1937': 517})\n",
      "\n",
      "Multiple attrs:\n",
      "defaultdict(<class 'int'>, {'1927': 758, '1926': 588, '1928': 535, '1930': 520, '1925': 803, '1934': 445, '1933': 450, '1932': 429, '1929': 537, '1931': 608, '1935': 321, '1938': 275, '1936': 273, '1939': 270, '1937': 291})\n",
      "\n",
      "\"Sure\" citations:\n",
      "defaultdict(<class 'int'>, {'1934': 121, '1926': 68, '1932': 76, '1928': 76, '1927': 130, '1933': 85, '1931': 92, '1925': 133, '1929': 81, '1930': 81, '1935': 85, '1938': 45, '1936': 59, '1939': 44, '1937': 63})\n",
      "Filtered citations:\n",
      "\n",
      "Stop subs:\n",
      "\n",
      "Multiple attrs:\n",
      "\n",
      "\"Sure\" citations:\n",
      "['Mt 3:3/J 1:23/Mk 1:3/L 3:4/Iz 40:3', 'Ex 20:15/Dt 5:19', 'Z 127:1', 'Ex 20:12/Dt 5:16/Ef 6:2', 'Gn 3:19', 'Pr 26:27', 'Ex 20:13/Dt 5:17', '2S 14:5', 'Ex 20:14/Dt 5:18', 'Iz 45:8', 'Pr 31:10', 'Ez 24:19']\n",
      "['Mt 5:38', 'Mt 3:3/J 1:23/Mk 1:3/L 3:4/Iz 40:3', 'L 2:14', 'Mt 11:28', 'Mt 6:11/L 11:3', 'Ex 20:12/Dt 5:16/Ef 6:2', 'Mt 27:25', 'Mt 16:18', 'L 18:42', 'L 20:25', 'Mt 20:16']\n",
      "['1J 5:6', 'R 13:11', 'Sk 5:29', '2P 1:17', 'Ex 20:12/Dt 5:16/Ef 6:2', '2K 1:2/Fp 1:2/2Te 1:2/1K 1:3/Ef 1:2/Ga 1:3', '1K 15:20', '2Tm 4:7', 'Zd 5:9', 'Sk 2:17', '2K 2:6', '2K 7:10']\n",
      "['Mt 5:38', 'Mt 3:3/J 1:23/Mk 1:3/L 3:4/Iz 40:3', 'L 2:14', 'Mt 11:28', 'Mt 6:11/L 11:3', 'Mt 27:25', 'Mt 16:18', 'L 18:42', 'L 20:25', 'Mt 20:16']\n",
      "['2Ma 14:25', 'Tob 5:11', 'Tob 8:10', 'Sir 51:24', 'Sir 10:27', 'Tob 2:13', 'Mou 16:24', '2Ma 14:26', 'Sir 36:12', 'Jud 13:24', 'Jud 13:15', 'Sir 13:8', '2Ma 2:6', 'Sir 19:22', 'Zuz 1:46', 'Sir 35:21', '2Ma 4:18', 'Sir 33:15', 'Mou 19:4']\n",
      "['Ex 20:2', 'Ex 20:3', 'Ex 20:4', 'Ex 20:5', 'Ex 20:6', 'Ex 20:7', 'Ex 20:8', 'Ex 20:9', 'Ex 20:10', 'Ex 20:11', 'Ex 20:12', 'Ex 20:13', 'Ex 20:14', 'Ex 20:15', 'Ex 20:16', 'Ex 20:17', 'Dt 5:6', 'Dt 5:7', 'Dt 5:8', 'Dt 5:9', 'Dt 5:10', 'Dt 5:11', 'Dt 5:12', 'Dt 5:13', 'Dt 5:14', 'Dt 5:15', 'Dt 5:16', 'Dt 5:17', 'Dt 5:18', 'Dt 5:19', 'Dt 5:20', 'Dt 5:21']\n",
      "['Ex 20:2/Dt 5:6', 'Ex 20:5', 'Ex 20:15/Dt 5:19', 'Ex 20:12/Dt 5:16/Ef 6:2', 'Ex 20:13/Dt 5:17', 'Ex 20:3/Dt 5:7', 'Ex 20:14/Dt 5:18', 'Dt 5:21', 'Ex 20:16/Dt 5:20', 'Dt 5:9', 'Ex 20:8']\n",
      "bible_stats.csv has not changed\n",
      "SBL_by_value_map_of_meanings_points.csv has been created\n",
      "SBL_deuterocanonical_books_subset_results_stats.csv has been created\n",
      "SBL_gospels_books_subset_results_stats.csv has been created\n",
      "journals_map_of_meanings.csv has not changed\n",
      "journals_map_of_meanings_points.csv has not changed\n",
      "journals_results_stats.csv has not changed\n",
      "journals_stats.csv has not changed\n",
      "SBL_map_of_meanings.csv has been created\n",
      "SBL_map_of_meanings_points.csv has been created\n",
      "SBL_map_of_meanings_treshold_1.csv has been created\n",
      "SBL_map_of_meanings_treshold_1_points.csv has been created\n",
      "SBL_new_testament_books_subset_results_stats.csv has been created\n",
      "SBL_new_testament_no_gospels_books_subset_results_stats.csv has been created\n",
      "SBL_old_testament_books_subset_results_stats.csv has been created\n",
      "runtimes_stats.csv has not changed\n",
      "SBL_shared_map_of_meanings_treshold_1.csv has been created\n",
      "SBL_shared_map_of_meanings_treshold_1_points.csv has been created\n",
      "SBL_ten_commandments_verses_subset_results_stats.csv has been created\n",
      "SBL_top_verse_results_stats.csv has been created\n",
      "SBL_verses_in_years_results_stats.csv has been created\n",
      "SBL_verse_results_stats.csv has been created\n",
      "years_results_stats.csv has not changed\n"
     ]
    }
   ],
   "source": [
    "get_overall_result_stats()\n",
    "results_in_years()\n",
    "analyse_verses()\n",
    "analyse_verses_top()\n",
    "analyse_verse_ids_counts_in_years(10)\n",
    "\n",
    "subset_statistics_books(top_x=10, subset_books=old_testament_books, resulst_prefix_name='old_testament')\n",
    "subset_statistics_books(top_x=10, subset_books=new_testament_books, resulst_prefix_name='new_testament')\n",
    "subset_statistics_books(top_x=10, subset_books=new_testament_books_no_gospels, resulst_prefix_name='new_testament_no_gospels')\n",
    "subset_statistics_books(top_x=10, subset_books=gospels, resulst_prefix_name='gospels')\n",
    "subset_statistics_books(top_x=10, subset_books=deuterocanoncal_books, resulst_prefix_name='deuterocanonical')\n",
    "subset_statistics_verses(verese_ids_to_plot=ten_commandments_verses, resulst_prefix_name='ten_commandments')\n",
    "\n",
    "network_graph_creation()\n",
    "network_graph_creation(out_filename='map_of_meanings_treshold_1.csv', value_treshold=1)\n",
    "select_verses_shared_by_journals(map_of_meanings_data='map_of_meanings_treshold_1.csv', points_data='map_of_meanings_treshold_1_points.csv')\n",
    "map_of_meanings_by_citation_count()\n",
    "map_of_meanings_just_journals(map_of_meanings_data='map_of_meanings_treshold_1.csv', points_data='map_of_meanings_treshold_1_points.csv')\n",
    "\n",
    "change_all_statistics_to_SBL()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer data for chart.js"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_flourish_to_chartjs(input_chart_csv:str, color_palette_rgb:list, input_metadata_csv='SBL_map_of_meanings_treshold_1_points.csv'):\n",
    "    \"\"\" This function transfers input statistics into a form suitable for javascript chart plotting with chart.js \"\"\"\n",
    "\n",
    "    input_df = pd.read_csv(os.path.join(RESULTS_PATH, 'statistics', input_chart_csv), quotechar='\"', delimiter=',', encoding='utf-8', index_col=0)\n",
    "    metadata_df = pd.read_csv(os.path.join(RESULTS_PATH, 'statistics', input_metadata_csv), quotechar='\"', delimiter=',', encoding='utf-8', index_col=0)\n",
    "\n",
    "    input_df = input_df.sort_values(by='year')\n",
    "    input_df = input_df.transpose()\n",
    "    input_df.columns = input_df.iloc[0]\n",
    "    input_df = input_df.drop(input_df.index[0])\n",
    "\n",
    "    print('[{')\n",
    "    for i, row_id in enumerate(input_df.index):\n",
    "        row_dict = input_df.loc[row_id].to_dict()\n",
    "        citations_in_years = []\n",
    "        for year in row_dict:\n",
    "            if type(year) == int:\n",
    "                citations_in_years.append(row_dict[year])\n",
    "\n",
    "        verse_color = str(color_palette_rgb[i])[1:-1]\n",
    "\n",
    "        print(f\"\\t\\tverseId: '{row_id}',\")\n",
    "        print(f\"\\t\\tcitations: {citations_in_years},\")\n",
    "        print(f\"\\t\\tbackgroundColor: 'rgb({verse_color}, 0.6)',\")\n",
    "        print(f\"\\t\\tborderColor: 'rgb({verse_color}, 0.9)',\")\n",
    "        print(f\"\\t\\thoverBackgroundColor: 'rgb({verse_color}, 1)',\")\n",
    "        print(f\"\\t\\tverseText: '{metadata_df.loc[row_id]['Verse text']}'\")\n",
    "        if i+1 == len(input_df.index):\n",
    "            print('\\t}')\n",
    "        else:\n",
    "            print('\\t},{')\n",
    "        \n",
    "    print('];')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### colour palletes\n",
    "const rgb_colours_blues = [(204, 232, 238), (102, 185, 203), (0, 139, 168), (0, 83, 101), (0, 28, 34)]\n",
    "const rgb_colours_green = [(179, 229, 212), (77, 194, 156), (0, 168, 113), (0, 118, 79), (0, 50, 34)]\n",
    "const rgb_colours_orange = [(247, 222, 191), (235, 177, 107), (227, 144, 43), (159, 101, 30), (68, 43, 13)]\n",
    "const rgb_colours_red = [(247, 194, 191), (235, 113, 107), (227, 52, 43), (159, 36, 30), (68, 16, 13)]\n",
    "\n",
    "const rgb_extra_colour_pt1 = [(33, 58, 63), (73, 99, 104), (0, 137, 112), (127, 209, 174), (184, 206, 170), (204, 232, 238), (233, 223, 247)]\n",
    "const rgb_extra_colour_pt2 = [(178, 168, 191), (131, 79, 98), (251, 179, 205), (252, 221, 203), (191, 90, 0), (131, 40, 0), (173, 137, 115)]\n",
    "const rgb_extra_colour_pt3 = [(250, 188, 42), (255, 202, 177), (243, 141, 104), (238, 108, 77), (247, 111, 142), (242, 186, 201), (127, 216, 190), (161, 252, 223), (59, 82, 73), (81, 152, 114)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rgb_colours_blues = [[204, 232, 238], [102, 185, 203], [0, 139, 168], [0, 83, 101], [0, 28, 34]]\n",
    "# rgb_colours_green = [[179, 229, 212], [77, 194, 156], [0, 168, 113], [0, 118, 79], [0, 50, 34]]\n",
    "# rgb_colours_orange = [[247, 222, 191], [235, 177, 107], [227, 144, 43], [159, 101, 30], [68, 43, 13]]\n",
    "# rgb_colours_red = [[247, 194, 191], [235, 113, 107], [227, 52, 43], [159, 36, 30], [68, 16, 13]]\n",
    "\n",
    "rgb_colours_blues = [[204, 232, 238], [102, 185, 203], [0, 139, 168], [0, 83, 101]]\n",
    "rgb_colours_green = [[179, 229, 212], [77, 194, 156], [0, 168, 113], [0, 118, 79]]\n",
    "rgb_colours_orange = [[247, 222, 191], [235, 177, 107], [227, 144, 43], [159, 101, 30]]\n",
    "rgb_colours_red = [[247, 194, 191], [235, 113, 107], [227, 52, 43], [159, 36, 30]]\n",
    "\n",
    "rgb_colours_blues.reverse()\n",
    "rgb_colours_green.reverse()\n",
    "rgb_colours_orange.reverse()\n",
    "rgb_colours_red.reverse()\n",
    "\n",
    "rgb_extra_colour_pt1 = [[33, 58, 63], [73, 99, 104], [0, 137, 112], [127, 209, 174], [184, 206, 170], [204, 232, 238], [233, 223, 247]]\n",
    "rgb_extra_colour_pt2 = [[178, 168, 191], [131, 79, 98], [251, 179, 205], [252, 221, 203], [191, 90, 0], [131, 40, 0], [173, 137, 115]]\n",
    "rgb_extra_colour_pt3 = [[250, 188, 42], [255, 202, 177], [243, 141, 104], [238, 108, 77], [247, 111, 142], [242, 186, 201], [127, 216, 190], [161, 252, 223], [59, 82, 73], [81, 152, 114]]\n",
    "\n",
    "color_palette_1 = []\n",
    "for i in range(0, 4):\n",
    "    color_palette_1.append(rgb_colours_blues[i])\n",
    "    color_palette_1.append(rgb_colours_green[i])\n",
    "    color_palette_1.append(rgb_colours_orange[i])\n",
    "    color_palette_1.append(rgb_colours_red[i])\n",
    "\n",
    "color_palette_2 = []\n",
    "for i in range(0, 3):\n",
    "    color_palette_2.append(rgb_extra_colour_pt1[i])\n",
    "    color_palette_2.append(rgb_extra_colour_pt2[i])\n",
    "    color_palette_2.append(rgb_extra_colour_pt3[i])\n",
    "\n",
    "color_palette_3 = []\n",
    "for i in range(3, 7):\n",
    "    color_palette_3.append(rgb_extra_colour_pt1[i])\n",
    "    color_palette_3.append(rgb_extra_colour_pt2[i])\n",
    "    color_palette_3.append(rgb_extra_colour_pt3[i])\n",
    "\n",
    "color_palette_large = []\n",
    "for i in range(0, 7):\n",
    "    color_palette_large.append(rgb_extra_colour_pt1[i])\n",
    "    color_palette_large.append(rgb_extra_colour_pt2[i])\n",
    "    color_palette_large.append(rgb_extra_colour_pt3[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[179, 229, 212]\n"
     ]
    }
   ],
   "source": [
    "print(color_palette_1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "const dataForPlottingTop = \n",
      "[{\n",
      "\t\tverseId: 'Matt 5:38',\n",
      "\t\tcitations: [2, 7, 5, 5, 8, 7, 7, 7, 13, 2, 5, 1, 4, 5, 2],\n",
      "\t\tbackgroundColor: 'rgb(0, 83, 101, 0.6)',\n",
      "\t\tborderColor: 'rgb(0, 83, 101, 0.9)',\n",
      "\t\thoverBackgroundColor: 'rgb(0, 83, 101, 1)',\n",
      "\t\tverseText: 'Slyšeli jste, že bylo řečeno: „Oko za oko, zub za zub.“'\n",
      "\t},{\n",
      "\t\tverseId: 'Matt 3:3/John 1:23/Mark 1:3/Luke 3:4/Isa 40:3',\n",
      "\t\tcitations: [4, 9, 11, 6, 5, 6, 9, 1, 4, 0, 3, 1, 1, 0, 5],\n",
      "\t\tbackgroundColor: 'rgb(0, 118, 79, 0.6)',\n",
      "\t\tborderColor: 'rgb(0, 118, 79, 0.9)',\n",
      "\t\thoverBackgroundColor: 'rgb(0, 118, 79, 1)',\n",
      "\t\tverseText: 'jakož psáno jest v knize řečí proroka Isaiáše: „Hlas volajícího na poušti: Připravte cestu Páně, přímé čiňte stezky jeho;'\n",
      "\t},{\n",
      "\t\tverseId: 'Luke 2:14',\n",
      "\t\tcitations: [7, 10, 11, 8, 4, 12, 8, 9, 11, 4, 2, 1, 5, 2, 3],\n",
      "\t\tbackgroundColor: 'rgb(159, 101, 30, 0.6)',\n",
      "\t\tborderColor: 'rgb(159, 101, 30, 0.9)',\n",
      "\t\thoverBackgroundColor: 'rgb(159, 101, 30, 1)',\n",
      "\t\tverseText: 'Sláva na výsostech Bohu, a na zemi pokoj, lidem dobrá vůle.'\n",
      "\t},{\n",
      "\t\tverseId: 'Matt 11:28',\n",
      "\t\tcitations: [1, 6, 4, 11, 2, 1, 4, 1, 2, 2, 1, 0, 2, 1, 2],\n",
      "\t\tbackgroundColor: 'rgb(159, 36, 30, 0.6)',\n",
      "\t\tborderColor: 'rgb(159, 36, 30, 0.9)',\n",
      "\t\thoverBackgroundColor: 'rgb(159, 36, 30, 1)',\n",
      "\t\tverseText: '„Pojďte ke mně všichni, kteří těžce pracujete a jste přetíženi, a já vám dám odpočinek.'\n",
      "\t},{\n",
      "\t\tverseId: 'Matt 6:11/Luke 11:3',\n",
      "\t\tcitations: [4, 3, 3, 0, 4, 6, 2, 3, 7, 3, 3, 1, 6, 5, 4],\n",
      "\t\tbackgroundColor: 'rgb(0, 139, 168, 0.6)',\n",
      "\t\tborderColor: 'rgb(0, 139, 168, 0.9)',\n",
      "\t\thoverBackgroundColor: 'rgb(0, 139, 168, 1)',\n",
      "\t\tverseText: 'Chléb náš vezdejší dej nám dnes.'\n",
      "\t},{\n",
      "\t\tverseId: 'Exod 20:15/Deut 5:19',\n",
      "\t\tcitations: [6, 3, 7, 3, 5, 3, 6, 1, 1, 2, 2, 2, 2, 0, 4],\n",
      "\t\tbackgroundColor: 'rgb(0, 168, 113, 0.6)',\n",
      "\t\tborderColor: 'rgb(0, 168, 113, 0.9)',\n",
      "\t\thoverBackgroundColor: 'rgb(0, 168, 113, 1)',\n",
      "\t\tverseText: 'Nepokradeš.'\n",
      "\t},{\n",
      "\t\tverseId: 'Matt 16:18',\n",
      "\t\tcitations: [16, 7, 4, 2, 3, 3, 6, 1, 2, 0, 1, 2, 2, 0, 0],\n",
      "\t\tbackgroundColor: 'rgb(227, 144, 43, 0.6)',\n",
      "\t\tborderColor: 'rgb(227, 144, 43, 0.9)',\n",
      "\t\thoverBackgroundColor: 'rgb(227, 144, 43, 1)',\n",
      "\t\tverseText: 'I já pravím tobě: Ty jsi Petr (t. j. skála), a na té skále vzdělám cirkev svou, a brány pekelné jí nepřemohou.'\n",
      "\t},{\n",
      "\t\tverseId: 'Exod 20:13/Deut 5:17',\n",
      "\t\tcitations: [11, 6, 11, 6, 16, 7, 6, 7, 5, 11, 6, 7, 2, 3, 3],\n",
      "\t\tbackgroundColor: 'rgb(227, 52, 43, 0.6)',\n",
      "\t\tborderColor: 'rgb(227, 52, 43, 0.9)',\n",
      "\t\thoverBackgroundColor: 'rgb(227, 52, 43, 1)',\n",
      "\t\tverseText: 'Nezabiješ.'\n",
      "\t},{\n",
      "\t\tverseId: 'Luke 20:25',\n",
      "\t\tcitations: [6, 4, 3, 5, 1, 4, 5, 0, 1, 2, 2, 1, 2, 2, 4],\n",
      "\t\tbackgroundColor: 'rgb(102, 185, 203, 0.6)',\n",
      "\t\tborderColor: 'rgb(102, 185, 203, 0.9)',\n",
      "\t\thoverBackgroundColor: 'rgb(102, 185, 203, 1)',\n",
      "\t\tverseText: 'I řekl jim: „Dávejte tedy, co je císařovo, císaři, a co jest Božího, Bohu.“'\n",
      "\t},{\n",
      "\t\tverseId: 'Matt 20:16',\n",
      "\t\tcitations: [5, 4, 3, 2, 1, 2, 4, 4, 6, 6, 3, 2, 2, 0, 2],\n",
      "\t\tbackgroundColor: 'rgb(77, 194, 156, 0.6)',\n",
      "\t\tborderColor: 'rgb(77, 194, 156, 0.9)',\n",
      "\t\thoverBackgroundColor: 'rgb(77, 194, 156, 1)',\n",
      "\t\tverseText: 'Tak budou poslední prvními a první posledními; neboť mnoho jest povolaných, ale málo vyvolených.“'\n",
      "\t}\n",
      "];\n",
      "\n",
      "const dataForPlottingTopEvangelia = \n",
      "[{\n",
      "\t\tverseId: 'Matt 5:38',\n",
      "\t\tcitations: [2, 7, 5, 5, 8, 7, 7, 7, 13, 2, 5, 1, 4, 5, 2],\n",
      "\t\tbackgroundColor: 'rgb(0, 83, 101, 0.6)',\n",
      "\t\tborderColor: 'rgb(0, 83, 101, 0.9)',\n",
      "\t\thoverBackgroundColor: 'rgb(0, 83, 101, 1)',\n",
      "\t\tverseText: 'Slyšeli jste, že bylo řečeno: „Oko za oko, zub za zub.“'\n",
      "\t},{\n",
      "\t\tverseId: 'Matt 3:3/John 1:23/Mark 1:3/Luke 3:4/Isa 40:3',\n",
      "\t\tcitations: [4, 9, 11, 6, 5, 6, 9, 1, 4, 0, 3, 1, 1, 0, 5],\n",
      "\t\tbackgroundColor: 'rgb(0, 118, 79, 0.6)',\n",
      "\t\tborderColor: 'rgb(0, 118, 79, 0.9)',\n",
      "\t\thoverBackgroundColor: 'rgb(0, 118, 79, 1)',\n",
      "\t\tverseText: 'jakož psáno jest v knize řečí proroka Isaiáše: „Hlas volajícího na poušti: Připravte cestu Páně, přímé čiňte stezky jeho;'\n",
      "\t},{\n",
      "\t\tverseId: 'Luke 2:14',\n",
      "\t\tcitations: [7, 10, 11, 8, 4, 12, 8, 9, 11, 4, 2, 1, 5, 2, 3],\n",
      "\t\tbackgroundColor: 'rgb(159, 101, 30, 0.6)',\n",
      "\t\tborderColor: 'rgb(159, 101, 30, 0.9)',\n",
      "\t\thoverBackgroundColor: 'rgb(159, 101, 30, 1)',\n",
      "\t\tverseText: 'Sláva na výsostech Bohu, a na zemi pokoj, lidem dobrá vůle.'\n",
      "\t},{\n",
      "\t\tverseId: 'Matt 11:28',\n",
      "\t\tcitations: [1, 6, 4, 11, 2, 1, 4, 1, 2, 2, 1, 0, 2, 1, 2],\n",
      "\t\tbackgroundColor: 'rgb(159, 36, 30, 0.6)',\n",
      "\t\tborderColor: 'rgb(159, 36, 30, 0.9)',\n",
      "\t\thoverBackgroundColor: 'rgb(159, 36, 30, 1)',\n",
      "\t\tverseText: '„Pojďte ke mně všichni, kteří těžce pracujete a jste přetíženi, a já vám dám odpočinek.'\n",
      "\t},{\n",
      "\t\tverseId: 'Matt 6:11/Luke 11:3',\n",
      "\t\tcitations: [4, 3, 3, 0, 4, 6, 2, 3, 7, 3, 3, 1, 6, 5, 4],\n",
      "\t\tbackgroundColor: 'rgb(0, 139, 168, 0.6)',\n",
      "\t\tborderColor: 'rgb(0, 139, 168, 0.9)',\n",
      "\t\thoverBackgroundColor: 'rgb(0, 139, 168, 1)',\n",
      "\t\tverseText: 'Chléb náš vezdejší dej nám dnes.'\n",
      "\t},{\n",
      "\t\tverseId: 'Matt 27:25',\n",
      "\t\tcitations: [4, 4, 5, 8, 2, 0, 7, 2, 1, 1, 0, 0, 1, 0, 0],\n",
      "\t\tbackgroundColor: 'rgb(0, 168, 113, 0.6)',\n",
      "\t\tborderColor: 'rgb(0, 168, 113, 0.9)',\n",
      "\t\thoverBackgroundColor: 'rgb(0, 168, 113, 1)',\n",
      "\t\tverseText: 'A odpověděv všecken lid, řekl: Krev jeho na nás, i na naše syny.'\n",
      "\t},{\n",
      "\t\tverseId: 'Matt 16:18',\n",
      "\t\tcitations: [16, 7, 4, 2, 3, 3, 6, 1, 2, 0, 1, 2, 2, 0, 0],\n",
      "\t\tbackgroundColor: 'rgb(227, 144, 43, 0.6)',\n",
      "\t\tborderColor: 'rgb(227, 144, 43, 0.9)',\n",
      "\t\thoverBackgroundColor: 'rgb(227, 144, 43, 1)',\n",
      "\t\tverseText: 'I já pravím tobě: Ty jsi Petr (t. j. skála), a na té skále vzdělám cirkev svou, a brány pekelné jí nepřemohou.'\n",
      "\t},{\n",
      "\t\tverseId: 'Luke 18:42',\n",
      "\t\tcitations: [8, 1, 6, 2, 5, 1, 1, 4, 2, 1, 0, 0, 1, 1, 2],\n",
      "\t\tbackgroundColor: 'rgb(227, 52, 43, 0.6)',\n",
      "\t\tborderColor: 'rgb(227, 52, 43, 0.9)',\n",
      "\t\thoverBackgroundColor: 'rgb(227, 52, 43, 1)',\n",
      "\t\tverseText: 'A Ježíš řekl jemu: Prohlédni. Víra tvá tě uzdravila.'\n",
      "\t},{\n",
      "\t\tverseId: 'Luke 20:25',\n",
      "\t\tcitations: [6, 4, 3, 5, 1, 4, 5, 0, 1, 2, 2, 1, 2, 2, 4],\n",
      "\t\tbackgroundColor: 'rgb(102, 185, 203, 0.6)',\n",
      "\t\tborderColor: 'rgb(102, 185, 203, 0.9)',\n",
      "\t\thoverBackgroundColor: 'rgb(102, 185, 203, 1)',\n",
      "\t\tverseText: 'I řekl jim: „Dávejte tedy, co je císařovo, císaři, a co jest Božího, Bohu.“'\n",
      "\t},{\n",
      "\t\tverseId: 'Matt 20:16',\n",
      "\t\tcitations: [5, 4, 3, 2, 1, 2, 4, 4, 6, 6, 3, 2, 2, 0, 2],\n",
      "\t\tbackgroundColor: 'rgb(77, 194, 156, 0.6)',\n",
      "\t\tborderColor: 'rgb(77, 194, 156, 0.9)',\n",
      "\t\thoverBackgroundColor: 'rgb(77, 194, 156, 1)',\n",
      "\t\tverseText: 'Tak budou poslední prvními a první posledními; neboť mnoho jest povolaných, ale málo vyvolených.“'\n",
      "\t}\n",
      "];\n",
      "\n",
      "const dataForPlottingTopNZ = \n",
      "[{\n",
      "\t\tverseId: '1John 5:6',\n",
      "\t\tcitations: [4, 2, 3, 0, 2, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1],\n",
      "\t\tbackgroundColor: 'rgb(0, 83, 101, 0.6)',\n",
      "\t\tborderColor: 'rgb(0, 83, 101, 0.9)',\n",
      "\t\thoverBackgroundColor: 'rgb(0, 83, 101, 1)',\n",
      "\t\tverseText: 'Ježíš Kristus jest ten, který přišel skrze vodu a krev. Nejen s vodou, ale s vodou a s krví. A Duch je toho svědkem, poněvadž Duch je pravda. '\n",
      "\t},{\n",
      "\t\tverseId: 'Rom 13:11',\n",
      "\t\tcitations: [1, 3, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0],\n",
      "\t\tbackgroundColor: 'rgb(0, 118, 79, 0.6)',\n",
      "\t\tborderColor: 'rgb(0, 118, 79, 0.9)',\n",
      "\t\thoverBackgroundColor: 'rgb(0, 118, 79, 1)',\n",
      "\t\tverseText: 'A vědouce ten čas: že již hodina jest, abychom ze sna povstali. Neboť nyní bližší jest naše spasení, nežli když sme uvěřili.'\n",
      "\t},{\n",
      "\t\tverseId: 'Acts 5:29',\n",
      "\t\tcitations: [4, 2, 2, 0, 1, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "\t\tbackgroundColor: 'rgb(159, 101, 30, 0.6)',\n",
      "\t\tborderColor: 'rgb(159, 101, 30, 0.9)',\n",
      "\t\thoverBackgroundColor: 'rgb(159, 101, 30, 1)',\n",
      "\t\tverseText: 'Petr a apoštolově odpověděli: „Více sluší poslouchati Boha než lidí.'\n",
      "\t},{\n",
      "\t\tverseId: '2Pet 1:17',\n",
      "\t\tcitations: [1, 2, 6, 0, 1, 1, 3, 0, 2, 0, 0, 0, 0, 1, 0],\n",
      "\t\tbackgroundColor: 'rgb(159, 36, 30, 0.6)',\n",
      "\t\tborderColor: 'rgb(159, 36, 30, 0.9)',\n",
      "\t\thoverBackgroundColor: 'rgb(159, 36, 30, 1)',\n",
      "\t\tverseText: 'Obdržel zajisté od Boha Otce čest i slávu, když se stal k němu takovýto hlas od velikolepé slávy: „Tento jest Syn můj milý, v němž jsem si zalíbil. (Jeho poslouchejte.“)'\n",
      "\t},{\n",
      "\t\tverseId: 'Exod 20:12/Deut 5:16/Eph 6:2',\n",
      "\t\tcitations: [3, 6, 2, 3, 4, 7, 0, 2, 2, 0, 2, 1, 0, 0, 4],\n",
      "\t\tbackgroundColor: 'rgb(0, 139, 168, 0.6)',\n",
      "\t\tborderColor: 'rgb(0, 139, 168, 0.9)',\n",
      "\t\thoverBackgroundColor: 'rgb(0, 139, 168, 1)',\n",
      "\t\tverseText: 'Cti otce svého i matku svou, jakož přikázal tobě Hospodin Bůh tvůj, aby se prodleli dnové tvoji, a aby tobě dobře bylo na zemi, kterouž Hospodin Bůh tvůj dá tobě.'\n",
      "\t},{\n",
      "\t\tverseId: '2Cor 1:2/Phil 1:2/2Thess 1:2/1Cor 1:3/Eph 1:2/Gal 1:3',\n",
      "\t\tcitations: [2, 3, 1, 1, 3, 2, 1, 1, 1, 0, 4, 5, 0, 1, 0],\n",
      "\t\tbackgroundColor: 'rgb(0, 168, 113, 0.6)',\n",
      "\t\tborderColor: 'rgb(0, 168, 113, 0.9)',\n",
      "\t\thoverBackgroundColor: 'rgb(0, 168, 113, 1)',\n",
      "\t\tverseText: 'Milost vám a pokoj od Boha, našeho Otce, a Pána Ježíše Krista, '\n",
      "\t},{\n",
      "\t\tverseId: '1Cor 15:20',\n",
      "\t\tcitations: [3, 1, 0, 3, 0, 1, 1, 1, 1, 2, 0, 1, 0, 0, 0],\n",
      "\t\tbackgroundColor: 'rgb(227, 144, 43, 0.6)',\n",
      "\t\tborderColor: 'rgb(227, 144, 43, 0.9)',\n",
      "\t\thoverBackgroundColor: 'rgb(227, 144, 43, 1)',\n",
      "\t\tverseText: 'Ale Kristus vstal z mrtvých, jako první ze zesnulých. '\n",
      "\t},{\n",
      "\t\tverseId: '2Tim 4:7',\n",
      "\t\tcitations: [1, 4, 3, 0, 2, 0, 1, 0, 1, 0, 1, 1, 3, 0, 0],\n",
      "\t\tbackgroundColor: 'rgb(227, 52, 43, 0.6)',\n",
      "\t\tborderColor: 'rgb(227, 52, 43, 0.9)',\n",
      "\t\thoverBackgroundColor: 'rgb(227, 52, 43, 1)',\n",
      "\t\tverseText: 'Dobrý boj sem bojoval, běh sem dokonal, víru sem zachoval.'\n",
      "\t},{\n",
      "\t\tverseId: 'Heb 5:9',\n",
      "\t\tcitations: [2, 2, 1, 1, 1, 1, 1, 3, 3, 1, 0, 2, 0, 0, 0],\n",
      "\t\tbackgroundColor: 'rgb(102, 185, 203, 0.6)',\n",
      "\t\tborderColor: 'rgb(102, 185, 203, 0.9)',\n",
      "\t\thoverBackgroundColor: 'rgb(102, 185, 203, 1)',\n",
      "\t\tverseText: 'a byv dokonán stal se příčinou věčné spásy všem, kteří ho poslouchají,'\n",
      "\t},{\n",
      "\t\tverseId: 'Acts 2:17',\n",
      "\t\tcitations: [1, 2, 0, 1, 0, 1, 4, 0, 2, 0, 1, 3, 0, 0, 0],\n",
      "\t\tbackgroundColor: 'rgb(77, 194, 156, 0.6)',\n",
      "\t\tborderColor: 'rgb(77, 194, 156, 0.9)',\n",
      "\t\thoverBackgroundColor: 'rgb(77, 194, 156, 1)',\n",
      "\t\tverseText: '»V posledních dnech, praví Bůh, vyleji část svého Ducha na všechny lidi; prorokovati budou vaši synové a vaše dcery; vaši jinoši budou míti vidění, vaši starci budou sníti sny;'\n",
      "\t},{\n",
      "\t\tverseId: '2Cor 2:6',\n",
      "\t\tcitations: [3, 0, 0, 1, 0, 3, 2, 0, 2, 2, 3, 1, 2, 0, 1],\n",
      "\t\tbackgroundColor: 'rgb(235, 177, 107, 0.6)',\n",
      "\t\tborderColor: 'rgb(235, 177, 107, 0.9)',\n",
      "\t\thoverBackgroundColor: 'rgb(235, 177, 107, 1)',\n",
      "\t\tverseText: 'Toto pokárání od většiny, kterého se mu dostalo, stačí; '\n",
      "\t},{\n",
      "\t\tverseId: '2Cor 7:10',\n",
      "\t\tcitations: [0, 2, 0, 1, 2, 2, 0, 1, 3, 0, 0, 0, 0, 2, 0],\n",
      "\t\tbackgroundColor: 'rgb(235, 113, 107, 0.6)',\n",
      "\t\tborderColor: 'rgb(235, 113, 107, 0.9)',\n",
      "\t\thoverBackgroundColor: 'rgb(235, 113, 107, 1)',\n",
      "\t\tverseText: 'Zármutek totiž, který jest podle Boha, působí pokání ke spáse, kterého se nelituje, ale zármutek světa působí smrt.'\n",
      "\t}\n",
      "];\n",
      "\n",
      "const dataForPlottingTopSZ = \n",
      "[{\n",
      "\t\tverseId: 'Matt 3:3/John 1:23/Mark 1:3/Luke 3:4/Isa 40:3',\n",
      "\t\tcitations: [4, 9, 11, 6, 5, 6, 9, 1, 4, 0, 3, 1, 1, 0, 5],\n",
      "\t\tbackgroundColor: 'rgb(0, 83, 101, 0.6)',\n",
      "\t\tborderColor: 'rgb(0, 83, 101, 0.9)',\n",
      "\t\thoverBackgroundColor: 'rgb(0, 83, 101, 1)',\n",
      "\t\tverseText: 'jakož psáno jest v knize řečí proroka Isaiáše: „Hlas volajícího na poušti: Připravte cestu Páně, přímé čiňte stezky jeho;'\n",
      "\t},{\n",
      "\t\tverseId: 'Exod 20:15/Deut 5:19',\n",
      "\t\tcitations: [6, 3, 7, 3, 5, 3, 6, 1, 1, 2, 2, 2, 2, 0, 4],\n",
      "\t\tbackgroundColor: 'rgb(0, 118, 79, 0.6)',\n",
      "\t\tborderColor: 'rgb(0, 118, 79, 0.9)',\n",
      "\t\thoverBackgroundColor: 'rgb(0, 118, 79, 1)',\n",
      "\t\tverseText: 'Nepokradeš.'\n",
      "\t},{\n",
      "\t\tverseId: 'Ps 127:1',\n",
      "\t\tcitations: [2, 2, 0, 2, 2, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0],\n",
      "\t\tbackgroundColor: 'rgb(159, 101, 30, 0.6)',\n",
      "\t\tborderColor: 'rgb(159, 101, 30, 0.9)',\n",
      "\t\thoverBackgroundColor: 'rgb(159, 101, 30, 1)',\n",
      "\t\tverseText: 'Píseň stupňů, Šalomounova. Nebude-li Hospodin stavěti domu, nadarmo usilují ti, kteříž stavějí jej; nebude-li Hospodin ostříhati města, nadarmo bdí strážný.'\n",
      "\t},{\n",
      "\t\tverseId: 'Exod 20:12/Deut 5:16/Eph 6:2',\n",
      "\t\tcitations: [3, 6, 2, 3, 4, 7, 0, 2, 2, 0, 2, 1, 0, 0, 4],\n",
      "\t\tbackgroundColor: 'rgb(159, 36, 30, 0.6)',\n",
      "\t\tborderColor: 'rgb(159, 36, 30, 0.9)',\n",
      "\t\thoverBackgroundColor: 'rgb(159, 36, 30, 1)',\n",
      "\t\tverseText: 'Cti otce svého i matku svou, jakož přikázal tobě Hospodin Bůh tvůj, aby se prodleli dnové tvoji, a aby tobě dobře bylo na zemi, kterouž Hospodin Bůh tvůj dá tobě.'\n",
      "\t},{\n",
      "\t\tverseId: 'Gen 3:19',\n",
      "\t\tcitations: [4, 1, 1, 0, 5, 3, 1, 0, 2, 2, 0, 0, 0, 0, 0],\n",
      "\t\tbackgroundColor: 'rgb(0, 139, 168, 0.6)',\n",
      "\t\tborderColor: 'rgb(0, 139, 168, 0.9)',\n",
      "\t\thoverBackgroundColor: 'rgb(0, 139, 168, 1)',\n",
      "\t\tverseText: 'V potu tváře jísti budeš chléb, dokud se nevrátíš do země, ze které jsi vzat. Ano, prach jsi, a v prach se navrátíš.'\n",
      "\t},{\n",
      "\t\tverseId: 'Prov 26:27',\n",
      "\t\tcitations: [3, 4, 2, 2, 3, 4, 3, 1, 2, 1, 0, 2, 3, 5, 1],\n",
      "\t\tbackgroundColor: 'rgb(0, 168, 113, 0.6)',\n",
      "\t\tborderColor: 'rgb(0, 168, 113, 0.9)',\n",
      "\t\thoverBackgroundColor: 'rgb(0, 168, 113, 1)',\n",
      "\t\tverseText: 'Kdo (jinému) jámu kopá, (sám) do ní padá, a kdo valí kámen, bude ním zavalen.'\n",
      "\t},{\n",
      "\t\tverseId: 'Exod 20:13/Deut 5:17',\n",
      "\t\tcitations: [11, 6, 11, 6, 16, 7, 6, 7, 5, 11, 6, 7, 2, 3, 3],\n",
      "\t\tbackgroundColor: 'rgb(227, 144, 43, 0.6)',\n",
      "\t\tborderColor: 'rgb(227, 144, 43, 0.9)',\n",
      "\t\thoverBackgroundColor: 'rgb(227, 144, 43, 1)',\n",
      "\t\tverseText: 'Nezabiješ.'\n",
      "\t},{\n",
      "\t\tverseId: '2Sam 14:5',\n",
      "\t\tcitations: [0, 1, 2, 1, 0, 1, 1, 1, 2, 1, 0, 0, 0, 0, 1],\n",
      "\t\tbackgroundColor: 'rgb(227, 52, 43, 0.6)',\n",
      "\t\tborderColor: 'rgb(227, 52, 43, 0.9)',\n",
      "\t\thoverBackgroundColor: 'rgb(227, 52, 43, 1)',\n",
      "\t\tverseText: 'I tázal se jí král: „Co je ti?\" A ona odpověděla: „Ach, vdovou jsem já, neboť umřel mi muž.'\n",
      "\t},{\n",
      "\t\tverseId: 'Exod 20:14/Deut 5:18',\n",
      "\t\tcitations: [3, 0, 3, 3, 3, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1],\n",
      "\t\tbackgroundColor: 'rgb(102, 185, 203, 0.6)',\n",
      "\t\tborderColor: 'rgb(102, 185, 203, 0.9)',\n",
      "\t\thoverBackgroundColor: 'rgb(102, 185, 203, 1)',\n",
      "\t\tverseText: 'Nesesmilníš.'\n",
      "\t},{\n",
      "\t\tverseId: 'Isa 45:8',\n",
      "\t\tcitations: [1, 0, 0, 1, 4, 2, 0, 0, 0, 3, 1, 0, 1, 0, 0],\n",
      "\t\tbackgroundColor: 'rgb(77, 194, 156, 0.6)',\n",
      "\t\tborderColor: 'rgb(77, 194, 156, 0.9)',\n",
      "\t\thoverBackgroundColor: 'rgb(77, 194, 156, 1)',\n",
      "\t\tverseText: 'Rosu dejte nebesa s hůry, a nejvyšší oblakové dštěte spravedlnost; otevři se země, a ať vzejde spasení, a spravedlnost ať spolu vykvete. Já Hospodin způsobím to.'\n",
      "\t},{\n",
      "\t\tverseId: 'Prov 31:10',\n",
      "\t\tcitations: [1, 2, 2, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0],\n",
      "\t\tbackgroundColor: 'rgb(235, 177, 107, 0.6)',\n",
      "\t\tborderColor: 'rgb(235, 177, 107, 0.9)',\n",
      "\t\thoverBackgroundColor: 'rgb(235, 177, 107, 1)',\n",
      "\t\tverseText: 'Ženu statečnou kdo nalezne? Nebo daleko nad perly cena její.'\n",
      "\t},{\n",
      "\t\tverseId: 'Ezek 24:19',\n",
      "\t\tcitations: [1, 3, 0, 0, 0, 0, 1, 1, 0, 2, 0, 1, 1, 1, 0],\n",
      "\t\tbackgroundColor: 'rgb(235, 113, 107, 0.6)',\n",
      "\t\tborderColor: 'rgb(235, 113, 107, 0.9)',\n",
      "\t\thoverBackgroundColor: 'rgb(235, 113, 107, 1)',\n",
      "\t\tverseText: 'I řekl mně lid: „Proč nám neoznamuješ, co znamenají tyto věci, jež činíš?\"'\n",
      "\t}\n",
      "];\n",
      "\n",
      "const dataForPlottingTopDesatero = \n",
      "[{\n",
      "\t\tverseId: 'Exod 20:2/Deut 5:6',\n",
      "\t\tcitations: [0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
      "\t\tbackgroundColor: 'rgb(0, 83, 101, 0.6)',\n",
      "\t\tborderColor: 'rgb(0, 83, 101, 0.9)',\n",
      "\t\thoverBackgroundColor: 'rgb(0, 83, 101, 1)',\n",
      "\t\tverseText: 'Já jsem Hospodin Bůh tvůj, kterýž jsem tě vyvedl z země Egyptské z domu služby.'\n",
      "\t},{\n",
      "\t\tverseId: 'Exod 20:5',\n",
      "\t\tcitations: [0, 0, 2, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
      "\t\tbackgroundColor: 'rgb(0, 118, 79, 0.6)',\n",
      "\t\tborderColor: 'rgb(0, 118, 79, 0.9)',\n",
      "\t\thoverBackgroundColor: 'rgb(0, 118, 79, 1)',\n",
      "\t\tverseText: 'Nebudeš se jim klaněti, aniž (jich) ctíti; jáť jsem Hospodin, Bůh tvůj silný a řevnivý, jenž do třetího a čtvrtého kolena stíhá syny za nepravosti těch otců, kteří mne nenávidí,'\n",
      "\t},{\n",
      "\t\tverseId: 'Exod 20:15/Deut 5:19',\n",
      "\t\tcitations: [6, 3, 7, 3, 5, 3, 6, 1, 1, 2, 2, 2, 2, 0, 4],\n",
      "\t\tbackgroundColor: 'rgb(159, 101, 30, 0.6)',\n",
      "\t\tborderColor: 'rgb(159, 101, 30, 0.9)',\n",
      "\t\thoverBackgroundColor: 'rgb(159, 101, 30, 1)',\n",
      "\t\tverseText: 'Nepokradeš.'\n",
      "\t},{\n",
      "\t\tverseId: 'Exod 20:12/Deut 5:16/Eph 6:2',\n",
      "\t\tcitations: [3, 6, 2, 3, 4, 7, 0, 2, 2, 0, 2, 1, 0, 0, 4],\n",
      "\t\tbackgroundColor: 'rgb(159, 36, 30, 0.6)',\n",
      "\t\tborderColor: 'rgb(159, 36, 30, 0.9)',\n",
      "\t\thoverBackgroundColor: 'rgb(159, 36, 30, 1)',\n",
      "\t\tverseText: 'Cti otce svého i matku svou, jakož přikázal tobě Hospodin Bůh tvůj, aby se prodleli dnové tvoji, a aby tobě dobře bylo na zemi, kterouž Hospodin Bůh tvůj dá tobě.'\n",
      "\t},{\n",
      "\t\tverseId: 'Exod 20:13/Deut 5:17',\n",
      "\t\tcitations: [11, 6, 11, 6, 16, 7, 6, 7, 5, 11, 6, 7, 2, 3, 3],\n",
      "\t\tbackgroundColor: 'rgb(0, 139, 168, 0.6)',\n",
      "\t\tborderColor: 'rgb(0, 139, 168, 0.9)',\n",
      "\t\thoverBackgroundColor: 'rgb(0, 139, 168, 1)',\n",
      "\t\tverseText: 'Nezabiješ.'\n",
      "\t},{\n",
      "\t\tverseId: 'Exod 20:3/Deut 5:7',\n",
      "\t\tcitations: [0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0],\n",
      "\t\tbackgroundColor: 'rgb(0, 168, 113, 0.6)',\n",
      "\t\tborderColor: 'rgb(0, 168, 113, 0.9)',\n",
      "\t\thoverBackgroundColor: 'rgb(0, 168, 113, 1)',\n",
      "\t\tverseText: 'Nebudeš míti bohů jiných přede mnou.'\n",
      "\t},{\n",
      "\t\tverseId: 'Exod 20:14/Deut 5:18',\n",
      "\t\tcitations: [3, 0, 3, 3, 3, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1],\n",
      "\t\tbackgroundColor: 'rgb(227, 144, 43, 0.6)',\n",
      "\t\tborderColor: 'rgb(227, 144, 43, 0.9)',\n",
      "\t\thoverBackgroundColor: 'rgb(227, 144, 43, 1)',\n",
      "\t\tverseText: 'Nesesmilníš.'\n",
      "\t},{\n",
      "\t\tverseId: 'Deut 5:21',\n",
      "\t\tcitations: [3, 2, 0, 1, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
      "\t\tbackgroundColor: 'rgb(227, 52, 43, 0.6)',\n",
      "\t\tborderColor: 'rgb(227, 52, 43, 0.9)',\n",
      "\t\thoverBackgroundColor: 'rgb(227, 52, 43, 1)',\n",
      "\t\tverseText: 'Nepožádáš manželky bližního svého, aniž požádáš domu bližního svého, pole jeho, neb služebníka jeho, aneb děvky jeho, vola jeho neb osla jeho, aneb čehokoli z těch věcí, kteréž jsou bližního tvého.'\n",
      "\t},{\n",
      "\t\tverseId: 'Exod 20:16/Deut 5:20',\n",
      "\t\tcitations: [1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "\t\tbackgroundColor: 'rgb(102, 185, 203, 0.6)',\n",
      "\t\tborderColor: 'rgb(102, 185, 203, 0.9)',\n",
      "\t\thoverBackgroundColor: 'rgb(102, 185, 203, 1)',\n",
      "\t\tverseText: 'Nepromluvíš proti bližnímu svému křivého svědectví.'\n",
      "\t},{\n",
      "\t\tverseId: 'Deut 5:9',\n",
      "\t\tcitations: [0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
      "\t\tbackgroundColor: 'rgb(77, 194, 156, 0.6)',\n",
      "\t\tborderColor: 'rgb(77, 194, 156, 0.9)',\n",
      "\t\thoverBackgroundColor: 'rgb(77, 194, 156, 1)',\n",
      "\t\tverseText: 'Nebudeš se jim klaněti, ani jich ctíti. Nebo já jsem Hospodin Bůh tvůj, Bůh silný, horlivý, navštěvující nepravost otců na synech do třetího i čtvrtého pokolení těch, kteříž nenávidí mne,'\n",
      "\t},{\n",
      "\t\tverseId: 'Exod 20:8',\n",
      "\t\tcitations: [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "\t\tbackgroundColor: 'rgb(235, 177, 107, 0.6)',\n",
      "\t\tborderColor: 'rgb(235, 177, 107, 0.9)',\n",
      "\t\thoverBackgroundColor: 'rgb(235, 177, 107, 1)',\n",
      "\t\tverseText: 'Pomni na den sobotní, abys jej světil.'\n",
      "\t}\n",
      "];\n"
     ]
    }
   ],
   "source": [
    "print('const dataForPlottingTop = ')\n",
    "transfer_flourish_to_chartjs(input_chart_csv='SBL_verses_in_years_results_stats.csv', color_palette_rgb=color_palette_1)\n",
    "\n",
    "print('\\nconst dataForPlottingTopEvangelia = ')\n",
    "transfer_flourish_to_chartjs(input_chart_csv='SBL_gospels_books_subset_results_stats.csv', color_palette_rgb=color_palette_1)\n",
    "\n",
    "print('\\nconst dataForPlottingTopNZ = ')\n",
    "transfer_flourish_to_chartjs(input_chart_csv='SBL_new_testament_no_gospels_books_subset_results_stats.csv', color_palette_rgb=color_palette_1)\n",
    "\n",
    "print('\\nconst dataForPlottingTopSZ = ')\n",
    "transfer_flourish_to_chartjs(input_chart_csv='SBL_old_testament_books_subset_results_stats.csv', color_palette_rgb=color_palette_1)\n",
    "\n",
    "print('\\nconst dataForPlottingTopDesatero = ')\n",
    "transfer_flourish_to_chartjs(input_chart_csv='SBL_ten_commandments_verses_subset_results_stats.csv', color_palette_rgb=color_palette_1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.9 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "87a9b2b242b38e94a819abbe84d1459ca0c92b18a62bfdb9bd39457d363f0a13"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
